{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['data_to_text', 'grammar_error_correction', 'title_generation',\n",
      "       'keyword_tagging', 'overlap_extraction', 'question_rewriting',\n",
      "       'eval_rougeL'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import collections\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "english_exp_names_1 = []\n",
    "english_exp_names_3 = ['english', 'english_stopword', 'english_delete_5', 'english_delete_10', \\\n",
    "        'english_insert_5', 'english_insert_10', \\\n",
    "        'english_replace_5', 'english_replace_10', 'english_shuffle_words', \\\n",
    "        'english_repeat_sentences', 'english_shuffle_sentences', 'english_shuffle_instruction']\n",
    "\n",
    "exact_match = collections.defaultdict(list)\n",
    "rougeL = collections.defaultdict(list)\n",
    "classifications = ['answerability_classification', 'cause_effect_classification', 'coreference_resolution', \\\n",
    "    'dialogue_act_recognition', 'word_analogy', 'textual_entailment']\n",
    "non_classifications = ['data_to_text', 'grammar_error_correction', 'title_generation',\\\n",
    "    'keyword_tagging', 'overlap_extraction', 'question_rewriting']\n",
    "for english_exp_name in english_exp_names_1:\n",
    "    metric_file = open('/home/gujiashe/Tk-Instruct/tk_outputs/output_{}/all_results.json'.format(english_exp_name), 'r')\n",
    "    metric = json.load(metric_file)\n",
    "\n",
    "\n",
    "    for classification in classifications:\n",
    "        exact_match[classification].append(metric['eval_exact_match_for_{}'.format(classification)])\n",
    "    exact_match['eval_exact_match'].append(metric['eval_exact_match'])\n",
    "    for non_classification in non_classifications:\n",
    "        rougeL[non_classification].append(metric['eval_rougeL_for_{}'.format(non_classification)])\n",
    "    rougeL['eval_rougeL'].append(metric['eval_rougeL'])\n",
    "\n",
    "metric_file = open('/home/gujiashe/Tk-Instruct/tk_outputs/output_{}/all_results.json'.format(\"english\"), 'r')\n",
    "metric = json.load(metric_file)\n",
    "metric_names = metric.keys()\n",
    "def create_dict(keys):\n",
    "    d = {}\n",
    "    for key in keys:\n",
    "        d[key] = []\n",
    "    return d    \n",
    "for english_exp_name in english_exp_names_3:\n",
    "    metric_samples = create_dict(metric_names)\n",
    "    metric_means = create_dict(metric_names)\n",
    "    metric_stds = create_dict(metric_names)\n",
    "    for index in [1, 2, 3]:\n",
    "        _english_exp_name = english_exp_name + \"_{}\".format(index)\n",
    "\n",
    "        metric_file = open('/home/gujiashe/Tk-Instruct/tk_outputs/output_{}/all_results.json'.format(_english_exp_name), 'r')\n",
    "        metric = json.load(metric_file)\n",
    "        for metric_name in metric_names:\n",
    "            metric_samples[metric_name].append(metric[metric_name])\n",
    "    \n",
    "    for metric_name in metric_names:\n",
    "        metric_means[metric_name] = round(np.mean(metric_samples[metric_name]), 1)\n",
    "    for metric_name in metric_names:\n",
    "        metric_stds[metric_name] = round(np.std(metric_samples[metric_name]), 1)\n",
    "\n",
    "    # metrics = metric_means\n",
    "\n",
    "    for classification in classifications:\n",
    "        metric_mean = metric_means['eval_exact_match_for_{}'.format(classification)]\n",
    "        metric_std = metric_stds['eval_exact_match_for_{}'.format(classification)]\n",
    "        exact_match[classification].append(str(metric_mean) + \"\\u00B1\" + str(metric_std))\n",
    "    \n",
    "    for non_classification in non_classifications:\n",
    "        metric_mean = metric_means['eval_rougeL_for_{}'.format(non_classification)]\n",
    "        metric_std = metric_stds['eval_rougeL_for_{}'.format(non_classification)]\n",
    "        rougeL[non_classification].append(str(metric_mean) + \"\\u00B1\" + str(metric_std))\n",
    "    exact_match['eval_exact_match'].append(str(metric_means['eval_exact_match']) + \"\\u00B1\" + str(metric_stds['eval_exact_match']))\n",
    "    rougeL['eval_rougeL'].append(str(metric_means['eval_rougeL']) + \"\\u00B1\" + str(metric_stds['eval_rougeL']))\n",
    "english_rougeL = pd.DataFrame(rougeL)\n",
    "english_rougeL.index = english_exp_names_1 + english_exp_names_3\n",
    "english_exact_match = pd.DataFrame(exact_match)\n",
    "english_exact_match.index = english_exp_names_1 + english_exp_names_3\n",
    "\n",
    "def generate_new_columns(columns):\n",
    "    new_columns = []\n",
    "    for c in columns:\n",
    "        new_column = []\n",
    "        for first in c.split('_'):\n",
    "            new_column.append(first[0].upper())\n",
    "        new_columns.append(\"\".join(new_column))\n",
    "    return new_columns\n",
    "print(english_rougeL.columns)\n",
    "english_exact_match.columns = generate_new_columns(english_exact_match.columns)\n",
    "english_rougeL.columns = generate_new_columns(english_rougeL.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AC</th>\n",
       "      <th>CEC</th>\n",
       "      <th>CR</th>\n",
       "      <th>DAR</th>\n",
       "      <th>WA</th>\n",
       "      <th>TE</th>\n",
       "      <th>EEM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>english</th>\n",
       "      <td>63.6±1.2</td>\n",
       "      <td>48.2±3.0</td>\n",
       "      <td>48.1±0.9</td>\n",
       "      <td>57.0±1.2</td>\n",
       "      <td>51.8±0.4</td>\n",
       "      <td>46.6±0.5</td>\n",
       "      <td>36.9±0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>english_stopword</th>\n",
       "      <td>63.2±0.6</td>\n",
       "      <td>49.0±0.5</td>\n",
       "      <td>49.1±2.2</td>\n",
       "      <td>49.9±1.7</td>\n",
       "      <td>50.5±1.9</td>\n",
       "      <td>44.5±0.6</td>\n",
       "      <td>36.1±0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>english_delete_5</th>\n",
       "      <td>60.7±2.0</td>\n",
       "      <td>49.1±2.3</td>\n",
       "      <td>47.2±0.7</td>\n",
       "      <td>53.1±1.0</td>\n",
       "      <td>52.8±0.5</td>\n",
       "      <td>44.7±1.1</td>\n",
       "      <td>36.0±0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>english_delete_10</th>\n",
       "      <td>61.1±2.0</td>\n",
       "      <td>50.7±1.2</td>\n",
       "      <td>49.5±1.3</td>\n",
       "      <td>52.9±4.5</td>\n",
       "      <td>50.8±1.3</td>\n",
       "      <td>44.0±1.4</td>\n",
       "      <td>36.0±0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>english_insert_5</th>\n",
       "      <td>60.8±1.4</td>\n",
       "      <td>48.5±0.4</td>\n",
       "      <td>49.5±1.0</td>\n",
       "      <td>55.3±1.7</td>\n",
       "      <td>51.0±1.2</td>\n",
       "      <td>45.7±0.7</td>\n",
       "      <td>36.3±0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>english_insert_10</th>\n",
       "      <td>60.4±1.4</td>\n",
       "      <td>48.7±1.3</td>\n",
       "      <td>47.5±0.9</td>\n",
       "      <td>56.6±0.9</td>\n",
       "      <td>52.5±1.6</td>\n",
       "      <td>44.6±0.5</td>\n",
       "      <td>36.2±0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>english_replace_5</th>\n",
       "      <td>62.0±0.5</td>\n",
       "      <td>48.3±0.7</td>\n",
       "      <td>48.3±0.4</td>\n",
       "      <td>54.4±2.7</td>\n",
       "      <td>50.0±0.7</td>\n",
       "      <td>45.0±0.8</td>\n",
       "      <td>36.0±0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>english_replace_10</th>\n",
       "      <td>60.3±0.7</td>\n",
       "      <td>49.2±1.5</td>\n",
       "      <td>47.7±1.0</td>\n",
       "      <td>50.0±0.9</td>\n",
       "      <td>51.6±1.9</td>\n",
       "      <td>43.9±1.6</td>\n",
       "      <td>35.7±0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>english_shuffle_words</th>\n",
       "      <td>59.4±1.8</td>\n",
       "      <td>46.5±0.9</td>\n",
       "      <td>46.7±0.8</td>\n",
       "      <td>49.7±2.2</td>\n",
       "      <td>50.5±2.0</td>\n",
       "      <td>41.5±0.4</td>\n",
       "      <td>34.3±0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>english_repeat_sentences</th>\n",
       "      <td>61.4±0.5</td>\n",
       "      <td>48.0±0.9</td>\n",
       "      <td>48.4±0.9</td>\n",
       "      <td>53.7±3.3</td>\n",
       "      <td>51.1±1.2</td>\n",
       "      <td>48.5±1.1</td>\n",
       "      <td>36.8±0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>english_shuffle_sentences</th>\n",
       "      <td>62.2±1.2</td>\n",
       "      <td>49.6±0.8</td>\n",
       "      <td>48.6±1.4</td>\n",
       "      <td>54.4±0.2</td>\n",
       "      <td>50.1±0.7</td>\n",
       "      <td>45.2±1.7</td>\n",
       "      <td>36.4±0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>english_shuffle_instruction</th>\n",
       "      <td>53.3±1.4</td>\n",
       "      <td>45.9±1.1</td>\n",
       "      <td>41.1±1.1</td>\n",
       "      <td>33.8±1.1</td>\n",
       "      <td>38.2±1.0</td>\n",
       "      <td>28.3±1.0</td>\n",
       "      <td>28.1±0.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   AC       CEC        CR       DAR        WA  \\\n",
       "english                      63.6±1.2  48.2±3.0  48.1±0.9  57.0±1.2  51.8±0.4   \n",
       "english_stopword             63.2±0.6  49.0±0.5  49.1±2.2  49.9±1.7  50.5±1.9   \n",
       "english_delete_5             60.7±2.0  49.1±2.3  47.2±0.7  53.1±1.0  52.8±0.5   \n",
       "english_delete_10            61.1±2.0  50.7±1.2  49.5±1.3  52.9±4.5  50.8±1.3   \n",
       "english_insert_5             60.8±1.4  48.5±0.4  49.5±1.0  55.3±1.7  51.0±1.2   \n",
       "english_insert_10            60.4±1.4  48.7±1.3  47.5±0.9  56.6±0.9  52.5±1.6   \n",
       "english_replace_5            62.0±0.5  48.3±0.7  48.3±0.4  54.4±2.7  50.0±0.7   \n",
       "english_replace_10           60.3±0.7  49.2±1.5  47.7±1.0  50.0±0.9  51.6±1.9   \n",
       "english_shuffle_words        59.4±1.8  46.5±0.9  46.7±0.8  49.7±2.2  50.5±2.0   \n",
       "english_repeat_sentences     61.4±0.5  48.0±0.9  48.4±0.9  53.7±3.3  51.1±1.2   \n",
       "english_shuffle_sentences    62.2±1.2  49.6±0.8  48.6±1.4  54.4±0.2  50.1±0.7   \n",
       "english_shuffle_instruction  53.3±1.4  45.9±1.1  41.1±1.1  33.8±1.1  38.2±1.0   \n",
       "\n",
       "                                   TE       EEM  \n",
       "english                      46.6±0.5  36.9±0.5  \n",
       "english_stopword             44.5±0.6  36.1±0.5  \n",
       "english_delete_5             44.7±1.1  36.0±0.6  \n",
       "english_delete_10            44.0±1.4  36.0±0.4  \n",
       "english_insert_5             45.7±0.7  36.3±0.2  \n",
       "english_insert_10            44.6±0.5  36.2±0.2  \n",
       "english_replace_5            45.0±0.8  36.0±0.3  \n",
       "english_replace_10           43.9±1.6  35.7±0.5  \n",
       "english_shuffle_words        41.5±0.4  34.3±0.3  \n",
       "english_repeat_sentences     48.5±1.1  36.8±0.3  \n",
       "english_shuffle_sentences    45.2±1.7  36.4±0.4  \n",
       "english_shuffle_instruction  28.3±1.0  28.1±0.1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_exact_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DTT</th>\n",
       "      <th>GEC</th>\n",
       "      <th>TG</th>\n",
       "      <th>KT</th>\n",
       "      <th>OE</th>\n",
       "      <th>QR</th>\n",
       "      <th>ER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>english</th>\n",
       "      <td>43.3±0.5</td>\n",
       "      <td>85.7±1.1</td>\n",
       "      <td>37.4±0.5</td>\n",
       "      <td>64.8±1.9</td>\n",
       "      <td>32.7±1.4</td>\n",
       "      <td>68.0±0.2</td>\n",
       "      <td>54.8±0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>english_stopword</th>\n",
       "      <td>43.8±0.4</td>\n",
       "      <td>85.2±0.5</td>\n",
       "      <td>37.2±0.3</td>\n",
       "      <td>63.6±0.3</td>\n",
       "      <td>34.2±1.0</td>\n",
       "      <td>68.0±0.3</td>\n",
       "      <td>53.8±0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>english_delete_5</th>\n",
       "      <td>42.2±0.3</td>\n",
       "      <td>84.1±0.7</td>\n",
       "      <td>37.2±0.3</td>\n",
       "      <td>64.2±1.2</td>\n",
       "      <td>37.4±1.4</td>\n",
       "      <td>67.4±0.2</td>\n",
       "      <td>53.7±0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>english_delete_10</th>\n",
       "      <td>42.2±0.5</td>\n",
       "      <td>85.0±2.0</td>\n",
       "      <td>36.8±0.2</td>\n",
       "      <td>64.0±1.0</td>\n",
       "      <td>34.4±1.8</td>\n",
       "      <td>67.5±0.0</td>\n",
       "      <td>53.6±0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>english_insert_5</th>\n",
       "      <td>41.8±0.4</td>\n",
       "      <td>85.3±0.8</td>\n",
       "      <td>37.2±0.2</td>\n",
       "      <td>61.1±2.6</td>\n",
       "      <td>38.5±2.5</td>\n",
       "      <td>67.5±0.5</td>\n",
       "      <td>54.0±0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>english_insert_10</th>\n",
       "      <td>42.3±0.5</td>\n",
       "      <td>86.6±0.4</td>\n",
       "      <td>37.0±0.2</td>\n",
       "      <td>65.8±1.2</td>\n",
       "      <td>36.7±1.9</td>\n",
       "      <td>67.3±0.3</td>\n",
       "      <td>53.8±0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>english_replace_5</th>\n",
       "      <td>42.7±0.3</td>\n",
       "      <td>85.1±1.1</td>\n",
       "      <td>37.1±0.4</td>\n",
       "      <td>63.5±2.3</td>\n",
       "      <td>35.0±1.2</td>\n",
       "      <td>67.8±0.2</td>\n",
       "      <td>54.0±0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>english_replace_10</th>\n",
       "      <td>42.5±0.4</td>\n",
       "      <td>84.0±1.5</td>\n",
       "      <td>36.9±0.4</td>\n",
       "      <td>65.6±1.6</td>\n",
       "      <td>36.0±3.3</td>\n",
       "      <td>68.2±0.5</td>\n",
       "      <td>53.6±0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>english_shuffle_words</th>\n",
       "      <td>44.9±0.4</td>\n",
       "      <td>84.6±0.7</td>\n",
       "      <td>36.3±0.4</td>\n",
       "      <td>62.4±0.2</td>\n",
       "      <td>33.8±3.6</td>\n",
       "      <td>67.7±0.1</td>\n",
       "      <td>52.1±0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>english_repeat_sentences</th>\n",
       "      <td>42.9±0.4</td>\n",
       "      <td>85.9±0.3</td>\n",
       "      <td>37.4±0.3</td>\n",
       "      <td>64.8±1.6</td>\n",
       "      <td>36.8±2.5</td>\n",
       "      <td>67.3±0.3</td>\n",
       "      <td>54.4±0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>english_shuffle_sentences</th>\n",
       "      <td>41.9±0.3</td>\n",
       "      <td>86.4±0.7</td>\n",
       "      <td>37.1±0.9</td>\n",
       "      <td>64.6±1.2</td>\n",
       "      <td>38.2±1.8</td>\n",
       "      <td>67.6±0.4</td>\n",
       "      <td>54.2±0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>english_shuffle_instruction</th>\n",
       "      <td>42.0±0.3</td>\n",
       "      <td>87.2±0.6</td>\n",
       "      <td>27.5±0.4</td>\n",
       "      <td>52.2±0.4</td>\n",
       "      <td>31.4±3.0</td>\n",
       "      <td>66.0±0.4</td>\n",
       "      <td>43.2±0.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  DTT       GEC        TG        KT        OE  \\\n",
       "english                      43.3±0.5  85.7±1.1  37.4±0.5  64.8±1.9  32.7±1.4   \n",
       "english_stopword             43.8±0.4  85.2±0.5  37.2±0.3  63.6±0.3  34.2±1.0   \n",
       "english_delete_5             42.2±0.3  84.1±0.7  37.2±0.3  64.2±1.2  37.4±1.4   \n",
       "english_delete_10            42.2±0.5  85.0±2.0  36.8±0.2  64.0±1.0  34.4±1.8   \n",
       "english_insert_5             41.8±0.4  85.3±0.8  37.2±0.2  61.1±2.6  38.5±2.5   \n",
       "english_insert_10            42.3±0.5  86.6±0.4  37.0±0.2  65.8±1.2  36.7±1.9   \n",
       "english_replace_5            42.7±0.3  85.1±1.1  37.1±0.4  63.5±2.3  35.0±1.2   \n",
       "english_replace_10           42.5±0.4  84.0±1.5  36.9±0.4  65.6±1.6  36.0±3.3   \n",
       "english_shuffle_words        44.9±0.4  84.6±0.7  36.3±0.4  62.4±0.2  33.8±3.6   \n",
       "english_repeat_sentences     42.9±0.4  85.9±0.3  37.4±0.3  64.8±1.6  36.8±2.5   \n",
       "english_shuffle_sentences    41.9±0.3  86.4±0.7  37.1±0.9  64.6±1.2  38.2±1.8   \n",
       "english_shuffle_instruction  42.0±0.3  87.2±0.6  27.5±0.4  52.2±0.4  31.4±3.0   \n",
       "\n",
       "                                   QR        ER  \n",
       "english                      68.0±0.2  54.8±0.4  \n",
       "english_stopword             68.0±0.3  53.8±0.4  \n",
       "english_delete_5             67.4±0.2  53.7±0.4  \n",
       "english_delete_10            67.5±0.0  53.6±0.3  \n",
       "english_insert_5             67.5±0.5  54.0±0.1  \n",
       "english_insert_10            67.3±0.3  53.8±0.0  \n",
       "english_replace_5            67.8±0.2  54.0±0.2  \n",
       "english_replace_10           68.2±0.5  53.6±0.6  \n",
       "english_shuffle_words        67.7±0.1  52.1±0.3  \n",
       "english_repeat_sentences     67.3±0.3  54.4±0.2  \n",
       "english_shuffle_sentences    67.6±0.4  54.2±0.2  \n",
       "english_shuffle_instruction  66.0±0.4  43.2±0.1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_rougeL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llllllll}\n",
      "\\toprule\n",
      "{} &        AC &       CEC &        CR &       DAR &        WA &        TE &       EEM \\\\\n",
      "\\midrule\n",
      "english                     &  63.6±1.2 &  48.2±3.0 &  48.1±0.9 &  57.0±1.2 &  51.8±0.4 &  46.6±0.5 &  36.9±0.5 \\\\\n",
      "english\\_stopword            &  63.2±0.6 &  49.0±0.5 &  49.1±2.2 &  49.9±1.7 &  50.5±1.9 &  44.5±0.6 &  36.1±0.5 \\\\\n",
      "english\\_delete\\_5            &  60.7±2.0 &  49.1±2.3 &  47.2±0.7 &  53.1±1.0 &  52.8±0.5 &  44.7±1.1 &  36.0±0.6 \\\\\n",
      "english\\_delete\\_10           &  61.1±2.0 &  50.7±1.2 &  49.5±1.3 &  52.9±4.5 &  50.8±1.3 &  44.0±1.4 &  36.0±0.4 \\\\\n",
      "english\\_insert\\_5            &  60.8±1.4 &  48.5±0.4 &  49.5±1.0 &  55.3±1.7 &  51.0±1.2 &  45.7±0.7 &  36.3±0.2 \\\\\n",
      "english\\_insert\\_10           &  60.4±1.4 &  48.7±1.3 &  47.5±0.9 &  56.6±0.9 &  52.5±1.6 &  44.6±0.5 &  36.2±0.2 \\\\\n",
      "english\\_replace\\_5           &  62.0±0.5 &  48.3±0.7 &  48.3±0.4 &  54.4±2.7 &  50.0±0.7 &  45.0±0.8 &  36.0±0.3 \\\\\n",
      "english\\_replace\\_10          &  60.3±0.7 &  49.2±1.5 &  47.7±1.0 &  50.0±0.9 &  51.6±1.9 &  43.9±1.6 &  35.7±0.5 \\\\\n",
      "english\\_repeat\\_sentences    &  61.4±0.5 &  48.0±0.9 &  48.4±0.9 &  53.7±3.3 &  51.1±1.2 &  48.5±1.1 &  36.8±0.3 \\\\\n",
      "english\\_shuffle\\_sentences   &  62.2±1.2 &  49.6±0.8 &  48.6±1.4 &  54.4±0.2 &  50.1±0.7 &  45.2±1.7 &  36.4±0.4 \\\\\n",
      "english\\_shuffle\\_words       &  59.4±1.8 &  46.5±0.9 &  46.7±0.8 &  49.7±2.2 &  50.5±2.0 &  41.5±0.4 &  34.3±0.3 \\\\\n",
      "english\\_shuffle\\_instruction &  53.3±1.4 &  45.9±1.1 &  41.1±1.1 &  33.8±1.1 &  38.2±1.0 &  28.3±1.0 &  28.1±0.1 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_29755/296510610.py:1: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  print(english_exact_match.to_latex())\n"
     ]
    }
   ],
   "source": [
    "print(english_exact_match.to_latex())\n",
    "# print(english_rougeL.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import collections\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "xlingual_exp_names_1 = []\n",
    "xlingual_exp_names_3 = ['xlingual', 'xlingual_stopword', 'xlingual_delete_5', 'xlingual_delete_10', \\\n",
    "        'xlingual_insert_5', 'xlingual_insert_10', \\\n",
    "        'xlingual_replace_5', 'xlingual_replace_10', \\\n",
    "        'xlingual_repeat_sentences', 'xlingual_shuffle_sentences', 'xlingual_shuffle_words', 'xlingual_shuffle_instruction']\n",
    "exact_match = collections.defaultdict(list)\n",
    "rougeL = collections.defaultdict(list)\n",
    "classifications = ['answerability_classification', 'cause_effect_classification', 'textual_entailment']\n",
    "non_classifications = ['title_generation']\n",
    "for xlingual_exp_name in xlingual_exp_names_1:\n",
    "    metric_file = open('/home/gujiashe/Tk-Instruct/tk_outputs/output_{}/all_results.json'.format(xlingual_exp_name), 'r')\n",
    "    metric = json.load(metric_file)\n",
    "\n",
    "\n",
    "    for classification in classifications:\n",
    "        exact_match[classification].append(metric['eval_exact_match_for_{}'.format(classification)])\n",
    "    exact_match['eval_exact_match'].append(metric['eval_exact_match'])\n",
    "    for non_classification in non_classifications:\n",
    "        rougeL[non_classification].append(metric['eval_rougeL_for_{}'.format(non_classification)])\n",
    "    rougeL['eval_rougeL'].append(metric['eval_rougeL'])\n",
    "\n",
    "metric_file = open('/home/gujiashe/Tk-Instruct/tk_outputs/output_{}/all_results.json'.format(\"xlingual\"), 'r')\n",
    "metric = json.load(metric_file)\n",
    "metric_names = metric.keys()\n",
    "def create_dict(keys):\n",
    "    d = {}\n",
    "    for key in keys:\n",
    "        d[key] = []\n",
    "    return d    \n",
    "for xlingual_exp_name in xlingual_exp_names_3:\n",
    "    metric_samples = create_dict(metric_names)\n",
    "    metric_means = create_dict(metric_names)\n",
    "    metric_stds = create_dict(metric_names)\n",
    "    for index in [1, 2, 3]:\n",
    "        _xlingual_exp_name = xlingual_exp_name + \"_{}\".format(index)\n",
    "\n",
    "        metric_file = open('/home/gujiashe/Tk-Instruct/tk_outputs/output_{}/all_results.json'.format(_xlingual_exp_name), 'r')\n",
    "        metric = json.load(metric_file)\n",
    "        for metric_name in metric_names:\n",
    "            metric_samples[metric_name].append(metric[metric_name])\n",
    "    for metric_name in metric_names:\n",
    "        metric_means[metric_name] = round(np.mean(metric_samples[metric_name]), 1)\n",
    "    for metric_name in metric_names:\n",
    "        metric_stds[metric_name] = round(np.std(metric_samples[metric_name]), 1)\n",
    "\n",
    "    # metrics = metric_means\n",
    "\n",
    "    for classification in classifications:\n",
    "        metric_mean = metric_means['eval_exact_match_for_{}'.format(classification)]\n",
    "        metric_std = metric_stds['eval_exact_match_for_{}'.format(classification)]\n",
    "        exact_match[classification].append(str(metric_mean) + \"\\u00B1\" + str(metric_std))\n",
    "    \n",
    "    for non_classification in non_classifications:\n",
    "        metric_mean = metric_means['eval_rougeL_for_{}'.format(non_classification)]\n",
    "        metric_std = metric_stds['eval_rougeL_for_{}'.format(non_classification)]\n",
    "        rougeL[non_classification].append(str(metric_mean) + \"\\u00B1\" + str(metric_std))\n",
    "    exact_match['eval_exact_match'].append(str(metric_means['eval_exact_match']) + \"\\u00B1\" + str(metric_stds['eval_exact_match']))\n",
    "    rougeL['eval_rougeL'].append(str(metric_means['eval_rougeL']) + \"\\u00B1\" + str(metric_stds['eval_rougeL']))\n",
    "xlingual_rougeL = pd.DataFrame(rougeL)\n",
    "xlingual_rougeL.index = xlingual_exp_names_1 + xlingual_exp_names_3\n",
    "xlingual_exact_match = pd.DataFrame(exact_match)\n",
    "xlingual_exact_match.index = xlingual_exp_names_1 + xlingual_exp_names_3\n",
    "\n",
    "\n",
    "def generate_new_columns(columns):\n",
    "    new_columns = []\n",
    "    for c in columns:\n",
    "        new_column = []\n",
    "        for first in c.split('_'):\n",
    "            new_column.append(first[0].upper())\n",
    "        new_columns.append(\"\".join(new_column))\n",
    "    return new_columns\n",
    "xlingual_exact_match.columns = generate_new_columns(xlingual_exact_match.columns)\n",
    "xlingual_rougeL.columns = generate_new_columns(xlingual_rougeL.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lllll}\n",
      "\\toprule\n",
      "{} &        AC &       CEC &        TE &       EEM \\\\\n",
      "\\midrule\n",
      "xlingual                     &  72.0±0.8 &  54.2±0.6 &  20.0±1.2 &  50.2±0.5 \\\\\n",
      "xlingual\\_stopword            &  69.7±1.9 &  54.8±0.2 &  19.0±1.4 &  50.6±0.1 \\\\\n",
      "xlingual\\_delete\\_5            &  74.0±1.4 &  55.0±0.5 &  18.0±2.5 &  50.9±0.5 \\\\\n",
      "xlingual\\_delete\\_10           &  73.0±2.9 &  54.6±0.6 &  21.0±1.9 &  50.7±0.5 \\\\\n",
      "xlingual\\_insert\\_5            &  70.3±5.2 &  54.4±0.6 &  18.4±1.7 &  50.3±0.4 \\\\\n",
      "xlingual\\_insert\\_10           &  69.3±4.1 &  55.7±0.3 &  19.6±0.6 &  51.4±0.3 \\\\\n",
      "xlingual\\_replace\\_5           &  69.3±4.1 &  54.2±1.3 &  20.8±0.3 &  50.2±1.0 \\\\\n",
      "xlingual\\_replace\\_10          &  67.0±7.9 &  54.2±0.3 &  17.4±0.8 &  49.9±0.1 \\\\\n",
      "xlingual\\_repeat\\_sentences    &  74.7±1.2 &  55.2±0.6 &  20.9±2.4 &  51.3±0.4 \\\\\n",
      "xlingual\\_shuffle\\_sentences   &  67.3±1.2 &  54.9±0.5 &  19.1±1.6 &  50.6±0.6 \\\\\n",
      "xlingual\\_shuffle\\_words       &  70.0±5.7 &  53.2±0.1 &  16.0±2.6 &  49.0±0.2 \\\\\n",
      "xlingual\\_shuffle\\_instruction &  40.0±2.9 &  52.6±0.4 &   5.3±0.7 &  46.6±0.5 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_35720/285899341.py:1: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  print(xlingual_exact_match.to_latex())\n"
     ]
    }
   ],
   "source": [
    "print(xlingual_exact_match.to_latex())\n",
    "# print(xlingual_rougeL.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {'english_exact_match': english_exact_match, 'english_rougeL': english_rougeL, \\\n",
    "    'xlingual_exact_match': xlingual_exact_match, 'xlingual_rougeL': xlingual_rougeL}\n",
    "for metric_name, metric_var in metrics.items():\n",
    "    metric_var.to_csv(metric_name+'_means.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import collections\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "english_exp_names_1 = []\n",
    "english_exp_names_3 = ['english_original_instruction', 'english_new_instruction']\n",
    "\n",
    "exact_match = collections.defaultdict(list)\n",
    "rougeL = collections.defaultdict(list)\n",
    "classifications = ['answerability_classification', 'cause_effect_classification', 'coreference_resolution', \\\n",
    "    'dialogue_act_recognition', 'word_analogy', 'textual_entailment']\n",
    "non_classifications = ['data_to_text', 'grammar_error_correction', 'title_generation',\\\n",
    "    'keyword_tagging', 'overlap_extraction', 'question_rewriting']\n",
    "for english_exp_name in english_exp_names_1:\n",
    "    metric_file = open('/home/gujiashe/Tk-Instruct/tk_outputs/output_{}/all_results.json'.format(english_exp_name), 'r')\n",
    "    metric = json.load(metric_file)\n",
    "\n",
    "\n",
    "    for classification in classifications:\n",
    "        exact_match[classification].append(metric['eval_exact_match_for_{}'.format(classification)])\n",
    "    exact_match['eval_exact_match'].append(metric['eval_exact_match'])\n",
    "    for non_classification in non_classifications:\n",
    "        rougeL[non_classification].append(metric['eval_rougeL_for_{}'.format(non_classification)])\n",
    "    rougeL['eval_rougeL'].append(metric['eval_rougeL'])\n",
    "\n",
    "metric_file = open('/home/gujiashe/Tk-Instruct/tk_outputs/output_{}/all_results.json'.format(\"english_original_instruction\"), 'r')\n",
    "metric = json.load(metric_file)\n",
    "metric_names = metric.keys()\n",
    "# print(metric)\n",
    "def create_dict(keys):\n",
    "    d = {}\n",
    "    for key in keys:\n",
    "        d[key] = []\n",
    "    return d    \n",
    "for english_exp_name in english_exp_names_3:\n",
    "    metric_samples = create_dict(metric_names)\n",
    "    metric_means = create_dict(metric_names)\n",
    "    metric_stds = create_dict(metric_names)\n",
    "    for index in [1, 2, 3]:\n",
    "        _english_exp_name = english_exp_name + \"_{}\".format(index)\n",
    "\n",
    "        metric_file = open('/home/gujiashe/Tk-Instruct/tk_outputs/output_{}/all_results.json'.format(_english_exp_name), 'r')\n",
    "        metric = json.load(metric_file)\n",
    "        for metric_name in metric:\n",
    "            if metric_name.endswith(f'_new_{index}'):\n",
    "                metric_name_pruned = metric_name.replace(f'_new_{index}', '')\n",
    "            else:\n",
    "                metric_name_pruned = metric_name\n",
    "            metric_samples[metric_name_pruned].append(metric[metric_name])\n",
    "    \n",
    "    for metric_name in metric_names:\n",
    "        metric_means[metric_name] = round(np.mean(metric_samples[metric_name]), 1)\n",
    "    for metric_name in metric_names:\n",
    "        metric_stds[metric_name] = round(np.std(metric_samples[metric_name]), 1)\n",
    "\n",
    "    # metrics = metric_means\n",
    "\n",
    "    for classification in classifications:\n",
    "        metric_mean = metric_means['eval_exact_match_for_{}'.format(classification)]\n",
    "        metric_std = metric_stds['eval_exact_match_for_{}'.format(classification)]\n",
    "        exact_match[classification].append(str(metric_mean) + \"\\u00B1\" + str(metric_std))\n",
    "    \n",
    "    for non_classification in non_classifications:\n",
    "        metric_mean = metric_means['eval_rougeL_for_{}'.format(non_classification)]\n",
    "        metric_std = metric_stds['eval_rougeL_for_{}'.format(non_classification)]\n",
    "        rougeL[non_classification].append(str(metric_mean) + \"\\u00B1\" + str(metric_std))\n",
    "    exact_match['eval_exact_match'].append(str(metric_means['eval_exact_match']) + \"\\u00B1\" + str(metric_stds['eval_exact_match']))\n",
    "    rougeL['eval_rougeL'].append(str(metric_means['eval_rougeL']) + \"\\u00B1\" + str(metric_stds['eval_rougeL']))\n",
    "english_rougeL = pd.DataFrame(rougeL)\n",
    "english_rougeL.index = english_exp_names_1 + english_exp_names_3\n",
    "english_exact_match = pd.DataFrame(exact_match)\n",
    "english_exact_match.index = english_exp_names_1 + english_exp_names_3\n",
    "\n",
    "def generate_new_columns(columns):\n",
    "    new_columns = []\n",
    "    for c in columns:\n",
    "        new_column = []\n",
    "        for first in c.split('_'):\n",
    "            new_column.append(first[0].upper())\n",
    "        new_columns.append(\"\".join(new_column))\n",
    "    return new_columns\n",
    "english_exact_match.columns = generate_new_columns(english_exact_match.columns)\n",
    "english_rougeL.columns = generate_new_columns(english_rougeL.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llllllll}\n",
      "\\toprule\n",
      "{} &        AC &       CEC &        CR &       DAR &        WA &        TE &       EEM \\\\\n",
      "\\midrule\n",
      "english\\_original\\_instruction &  67.5±0.0 &  68.5±0.0 &  60.0±0.0 &  44.5±0.0 &  44.0±0.0 &  44.5±0.0 &  36.8±0.0 \\\\\n",
      "english\\_new\\_instruction      &  67.3±1.0 &  69.3±0.2 &  56.8±1.6 &  43.3±2.7 &  43.2±1.9 &  52.7±5.8 &  37.1±0.5 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\\begin{tabular}{llllllll}\n",
      "\\toprule\n",
      "{} &       DTT &       GEC &        TG &        KT &        OE &        QR &        ER \\\\\n",
      "\\midrule\n",
      "english\\_original\\_instruction &  44.1±0.0 &  83.3±0.0 &  25.0±0.0 &  72.9±0.0 &  32.2±0.0 &  81.6±0.0 &  57.8±0.0 \\\\\n",
      "english\\_new\\_instruction      &  44.2±0.3 &  84.3±0.3 &  24.6±0.2 &  72.0±0.6 &  32.7±0.1 &  81.3±0.2 &  58.0±0.5 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10066/2079488218.py:1: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  print(english_exact_match.to_latex())\n",
      "/tmp/ipykernel_10066/2079488218.py:2: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  print(english_rougeL.to_latex())\n"
     ]
    }
   ],
   "source": [
    "print(english_exact_match.to_latex())\n",
    "print(english_rougeL.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AC</th>\n",
       "      <th>CEC</th>\n",
       "      <th>CR</th>\n",
       "      <th>DAR</th>\n",
       "      <th>WA</th>\n",
       "      <th>TE</th>\n",
       "      <th>EEM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>english_new_instruction</th>\n",
       "      <td>67.3±1.0</td>\n",
       "      <td>69.3±0.2</td>\n",
       "      <td>56.8±1.6</td>\n",
       "      <td>43.3±2.7</td>\n",
       "      <td>43.2±1.9</td>\n",
       "      <td>52.7±5.8</td>\n",
       "      <td>37.1±0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               AC       CEC        CR       DAR        WA  \\\n",
       "english_new_instruction  67.3±1.0  69.3±0.2  56.8±1.6  43.3±2.7  43.2±1.9   \n",
       "\n",
       "                               TE       EEM  \n",
       "english_new_instruction  52.7±5.8  37.1±0.5  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_exact_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DTT</th>\n",
       "      <th>GEC</th>\n",
       "      <th>TG</th>\n",
       "      <th>KT</th>\n",
       "      <th>OE</th>\n",
       "      <th>QR</th>\n",
       "      <th>ER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>english_new_instruction</th>\n",
       "      <td>44.2±0.3</td>\n",
       "      <td>84.3±0.3</td>\n",
       "      <td>24.6±0.2</td>\n",
       "      <td>72.0±0.6</td>\n",
       "      <td>32.7±0.1</td>\n",
       "      <td>81.3±0.2</td>\n",
       "      <td>58.0±0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              DTT       GEC        TG        KT        OE  \\\n",
       "english_new_instruction  44.2±0.3  84.3±0.3  24.6±0.2  72.0±0.6  32.7±0.1   \n",
       "\n",
       "                               QR        ER  \n",
       "english_new_instruction  81.3±0.2  58.0±0.5  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_rougeL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test tk_instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a am student I'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "def random_shuffle(Definition):\n",
    "\n",
    "    token_list = Definition.split()\n",
    "    random.shuffle(token_list)\n",
    "    return \" \".join(token_list)\n",
    "random_shuffle(\"I am a student\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"allenai/tk-instruct-3b-def\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"allenai/tk-instruct-3b-def\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n"
     ]
    }
   ],
   "source": [
    "input_ids = tokenizer.encode(\n",
    "        # \"Definition: return the currency of the country. Now complete the following example - Input: China. Output:\", \n",
    "        \"فتوسنتز فرایندی زیست‌شیمیایی است که در آن، انرژی نورانی خورشید توسط گیاهان و برخی از باکتری‌ها به انرژی شیمیایی ذخیره‌شده در مواد غذایی آن‌ها تبدیل می‌شود. کمابیش همهٔ جانداران روی زمین به آن وابسته‌اند. در عمل فتوسنتز، اندام‌هایی مانند برگ که دارای سبزینه هستند، کربن دی‌اکسید، آب و نور را جذب کرده و به کلروپلاست می‌رسانند. طی واکنش‌هایی که درون کلروپلاست انجام می‌گیرد، این مواد به اکسیژن و کربوهیدرات‌ها تبدیل می‌شوند. همه اکسیژن کنونی موجود بر روی زمین، فراوردهٔ فتوسنتز است. برخی از کربوهیدرات‌های مهم تولیدشده مانند گلوکز، می‌توانند به دیگر مواد آلی، لیپیدها، نشاسته، سلولز و پروتئین تبدیل شوند که برای تبدیل‌شدن به پروتئین، نیاز به نیتروژن دارند. ژان باپتیست ون هلمونت، یکی از نخستین آزمایش‌های مربوط به فتوسنتز را انجام داد. همه بخش‌های سبزرنگ گیاه، قادر به انجام عمل فتوسنتز هستند. مادهٔ سبز موجود در گیاهان که سبزینه یا کلروفیل نام دارد، آغازکنندهٔ واکنش‌های فتوسنتز است. فتوسنتز در اندام‌هایی که فاقد سبزینه هستند، انجام نمی‌گیرد.\",\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "output = model.generate(input_ids, max_length=10)\n",
    "output = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load ni_dataset_crud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-ef21323b704ac40a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset natural_instructions/default to ../cache/natural_instructions/default-ef21323b704ac40a/2.0.0/241d69c989a9550d22fa88048671e911038842f20f900bbc514909343345ccac...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b0312d729bc472b99aa7d5918b49bbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1568fceb5e284eec96ad4ae92a11401a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7f587ee55194352a774029068db26cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset natural_instructions downloaded and prepared to ../cache/natural_instructions/default-ef21323b704ac40a/2.0.0/241d69c989a9550d22fa88048671e911038842f20f900bbc514909343345ccac. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3349afa049904db8b8732bbfc4b9fe7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Task': \"['translation', 'en-es']\", 'Contributors': 'instruction_induction', 'Source': ['instruction_induction'], 'URL': ['instruction_induction'], 'Categories': ['instruction_induction'], 'Reasoning': ['instruction_induction'], 'Definition': ['Translate to Spanish'], 'Positive Examples': [], 'Negative Examples': [], 'Input_language': ['English'], 'Output_language': ['English'], 'Instruction_language': ['English'], 'Domains': ['instruction_induction'], 'Instance': {'input': 'ile', 'output': ['montón']}}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, load_metric\n",
    "from transformers import set_seed\n",
    "set_seed(0)\n",
    "raw_datasets = load_dataset(\n",
    "    \"../src/induction_dataset.py\", \n",
    "    data_dir='../induction_data/', \n",
    "    task_dir='../induction_data/tasks/', \n",
    "    cache_dir='../cache/',\n",
    "    max_num_instances_per_task=100,\n",
    "    max_num_instances_per_eval_task=100,\n",
    "    download_mode = 'reuse_cache_if_exists'\n",
    ")\n",
    "print(raw_datasets['test'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-8e82d9b055b27d6b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset natural_instructions/default (download: Unknown size, generated: 55.96 MiB, post-processed: Unknown size, total: 55.96 MiB) to /home/gujiashe/.cache/huggingface/datasets/natural_instructions/default-8e82d9b055b27d6b/2.0.0/c0040095172c0d76abd173b8640d8a5c5293cbc538c41e16bb88bdb4d0bb6a46...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37e86ff2749846c4a1baa42cefa15fbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3ea3565a5874bf7907530ab88c0bd40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a13d833adfc942ce929e60edef907cbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset natural_instructions downloaded and prepared to /home/gujiashe/.cache/huggingface/datasets/natural_instructions/default-8e82d9b055b27d6b/2.0.0/c0040095172c0d76abd173b8640d8a5c5293cbc538c41e16bb88bdb4d0bb6a46. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27c3430b2b3e4cabbd8770335ff3d966",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Read the passage and find the corresponding pronoun for the given name. The pronoun should match the given blank(_). The word between ** ** is the target name. The pronoun should be one of 'her', 'him', 'he', 'she' and 'his' with proper casing based on the position in the passage.\"]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, load_metric\n",
    "from transformers import set_seed\n",
    "set_seed(0)\n",
    "raw_datasets = load_dataset(\n",
    "    \"../src/ni_dataset.py\", \n",
    "    data_dir='../data/splits/default', \n",
    "    task_dir='../data/tasks', \n",
    "    # cache_dir='../cache/',\n",
    "    max_num_instances_per_task=100,\n",
    "    max_num_instances_per_eval_task=100,\n",
    "    # download_mode = 'reuse_cache_if_exists'\n",
    "    download_mode=\"force_redownload\"\n",
    ")\n",
    "print(raw_datasets['validation'][101]['Definition'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-ec6c0847c0c95340\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset natural_instructions/default to ../cache/natural_instructions/default-ec6c0847c0c95340/2.0.0/87c02665c2a1f7d0bece2821b9c4eacff1cc435986764bf7dafcb7d4e1c2f7f7...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4905e9c981d54ff1952a8c15ccbc5e17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31dcb7a110ba496c96a6e0773daae562",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Definition_native:  Generate an appropriate title for the given text. The generated title must be short and include the main topic of the text. The preferred titles are under fifteen words.\n",
      "Definition_change:  Generate an additional title for the given text. The main titles must be short to include the main titles and the title. The main titles are in fifteen words.\n",
      "Definition_native:  Read the passage and find the corresponding pronoun for the given name. The pronoun should match the given blank(_). The word between ** ** is the target name. The pronoun should be one of 'her', 'him', 'he', 'she' and 'his' with proper casing based on the position in the passage.\n",
      "Definition_change:  Read the passage and.. the pronoun for the given name. The pronoun should match the given blank ( _ ). The word between * * * * is the target name. The pronoun should be one of'her ','him ','he ','her'and'his'with proper casing based on the position in the passage.\n",
      "Definition_native:  Determine whether the two given sentences clearly agree with each other (entailment), disagree with each other (contradiction), or if this cannot be determined (neutral). Answer must be the letters E, C, and N, respectively.\n",
      "Definition_change:  Determine whether the two given sentences can agree with each other ( entailment ), disagree with each other ( contradiction ), or if this cannot be determined ( neutral ). Answer must be the letters E, C, and N, respectively.\n",
      "Definition_native:  You are given two sentences. You have to find if there is entailment or agreement of the Hypothesis by the Premise. From the given pair of sentences, you should identify if there is enough information in the Premise to support the claim made in the Hypothesis. The Premise may not exactly be the same as Hypothesis. Your task is to return 'entails' if the premise supports hypothesis else return 'neutral'.\n",
      "Definition_change:  You are given two sentences. You have to find if there is entailment or agreement of the Hypothesis by the Premise. From the given pair of sentences, you should identify if there is enough information in the Premise to support the claim made in the Hypothesis. The Premise may not exactly be the same as Hypothesis. Your sentence is that return'entails'if the premise supports hypothesis else return'neutral '.\n",
      "Definition_native:  In this task, you're given a statement, and three sentences as choices. Your job is to determine which sentence clearly disagrees with the statement. Indicate your answer as '1', '2', or '3' corresponding to the choice number of the selected sentence.\n",
      "Definition_change:  In this task, you've given a statement, and three, as choices. Your job is to determine the sentence that disagrees with the statement. Indicate your answer as'1 ','2 ', and'3'corresponding to the choice number of the selected sentence.\n",
      "Definition_native:  In this task, you're given an ambiguous question (which can be answered in more than one way). Your task is to write a question that clarifies the given question in such a way that the generated question has one unique answer.\n",
      "Definition_change:  In this case, you'll write an ambiguous question ( which can be answered in more than one way ). Yours is to write a question that clarifies the generated question in the same way that the generated question have one unique answer.\n",
      "Definition_native:  In this task, you are given a premise sentence, two possible options and a question word. If the question was cause you should select the option that is a possible cause of the premise sentence, and if the question word was effect you should find the option which is a possible effect of the premise sentence. Answer with \"A\" or \"B\".\n",
      "Definition_change:  In this task, you should find a premise sentence, two possible options and a question word. If the question was cause you should select the option that is a possible cause of the question word. and if the question word was not you should find the option which is a possible effect of the premise sentence. Answer with \" A \" or \" B \".\n",
      "Definition_native:  In this task, you're given two sentences. Indicate if the first sentence clearly entails the second sentence (i.e., one can conclude the 2nd sentence by reading the 1st one). Indicate your answer with '1' if the first sentence entails the second sentence, otherwise answer with '0'.\n",
      "Definition_change:  In this task, you're given two sentences. Indicate if the first sentence clearly entails the second sentence ( i. e., one can conclude the 2nd sentence by reading the 1st one ),, your answer with'1'if the first sentence is the second sentence, your answer with'1 '.\n",
      "Definition_native:  In this task, you are given a text of the article. Your task is to generate a headline (title) for this article.\n",
      "Definition_change:  In this case, you are given the copy of the article. The task is to generate the source ( a ) for the article.\n",
      "Definition_native:  In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\".\n",
      "Definition_change:  In this task, you will be presented with a premise and a second sentence. See whether the hypothesis, entails ( supports ), contradicts ( opposes ), or is presented with respect to the given second sentence. Please presented with \" Contradiction \", \" Neutrality \" or \" Entailment \".\n",
      "Definition_native:  In this task, you will be given a sentence, and you need to identify the set of coreference words. Coreferences are generally a set of words in the text that refer to the same person or thing. Your output set of coreference words must be strictly present in the given input sentence. Do not use any outside knowledge to create the set of coreference words. If there is a 'the' article before the person or thing you should include 'the' as well. Please separate the coreference words by commas in the output.\n",
      "Definition_change:  In this task, you will be given a sentence, and you need to identify the set of coreference words. Coreferences are not a set of words in the text that relate to the same person or thing. Your output set of coreference words must be strictly present in the given input sentence. Do not use any outside knowledge to create the set of coreference words. If there is a'the'article before a person or thing you should include'the'as well. Please separate the coreference words by commas in the output.\n",
      "Definition_native:  In this task, you're given a paragraph from the research paper and your task is to generate a suitable title for the research paper based on the given paper. Under 100 words is a good title length.\n",
      "Definition_change:  In this task, you're given a title from the research paper and your task is to generate a good title from the research paper length on a given paper. The 100 titles is a good title length.\n",
      "Definition_native:  You are given a sentence from a conversation between a human and a virtual assistant. Your task is to classify the sentence into one of the following five action categories - INFORM, INFORM_INTENT, OFFER, REQUEST, REQUEST_ALTS. If the sentence is about informing something, generate 'INFORM'. If it is about requesting something, generate 'REQUEST'. If the sentence mentions requesting an alternative option than the one provided, generate 'REQUEST_ALTS'. Similarly, generate 'OFFER' if the sentence is offering some information. If the sentence is about showing intent to do something, generate 'INFORM_INTENT'.\n",
      "Definition_change:  You are given a sentence from a conversation between a human and a virtual assistant. Your task is to classify the sentence into one of the following five action categories - INFORM, INFORM _ INTENT, OFFER, REQUEST, REQUEST _ ALTS. If the sentence is about informing something, generate'INFORM '. If it is about requesting something, generate'REQUEST '. If it is about requesting an alternative option than the one provided, generate'REQUEST _ ALTS '. Similarly, generate'OFFER'if the sentence is offering some information. If the sentence is about showing intent to do something, generate'INFORM _ INTENT '.\n",
      "Definition_native:  In this task you will be given a claim and a perspective. You should determine whether that perspective supports or undermines the claim. If the perspective could possibly convince someone with different view, it is supporting, otherwise it is undermining.\n",
      "Definition_change:  In this task you should be given a view and a perspective. You should determine whether that perspective supports or undermines the perspective. If the perspective could possibly convince someone to the view, it is supporting, otherwise it is undermining.\n",
      "Definition_native:  Given a paragraph about cooking, and a set of conversational questions and answers about the paragraph, say whether the passage contains sufficient information to answer the follow-up question. Say Yes if it is answerable; otherwise, say No. The paragraph has the prefix 'CONTEXT:'. Each conversation question has a prefix `Q:` followed by the answer prefix `A:`, and the follow-up question has a prefix `FOLLOWUP_Q:`.\n",
      "Definition_change:  Given a paragraph about cooking, say a number of conversation questions and answers about the paragraph, say whether the passage contains sufficient information to answer the follow - up question. Say No if it is No ; otherwise, say No. The paragraph has a prefix'Q : '. Each conversation question has a prefix Q : followed by the answer prefix A :, and the follow - up question has a prefix FOLLOWUP _ Q :.\n",
      "Definition_native:  Generate a topic word for the given sentence. A topic word is usually the name of a person, place, animal, concept or object the sentence is focusing on.\n",
      "Definition_change:  Generate a topic word for the given sentence. A topic word is usually the name of a person, place, animal, concept, object topic sentence is focusing on.\n",
      "Definition_native:  Given an abstract of a paper, generate a title for this paper such that conveys the key focus of the paper.\n",
      "Definition_change:  Given an image of a paper to generate a title of a title such that conveys the the focus of the paper.\n",
      "Definition_native:  You will be given one or more triples. The second part of each triple shows the relation between the first and the third element. Your task is to write a simple and short piece of text (sentence(s)) that describes the triples in natural language.\n",
      "Definition_change:  You will be given one or two triples. The second part of each triple shows the difference between the first and the third element. Your duty is to write a simple and short piece of the ( sentence ( s ), that represent the triples in natural language.\n",
      "Definition_native:  Given a paragraph from a Wikipedia article about some topic, and a question related to the topic, determine whether the question is answerable from the paragraph. If the question is answerable, answer \"True\", otherwise, answer \"False\".\n",
      "Definition_change:  Given a article from a Wikipedia article, the topic, and a question related to the topic, and whether the question is answerable from the paragraph. If the question is answerable, answer \" Good \", otherwise, answer \" False \".\n",
      "Definition_native:  You will see a sentence and a given pronoun. Answer with the word in the sentence to which the pronoun is referring.\n",
      "Definition_change:  You can see the sentence to a given pronoun. Answer to the word in the sentence to a given pronoun...\n",
      "Definition_native:  In this task, you are given a context tweet, a question and corresponding answer of given question. Your task is to classify given passage into two categories: (1) \"yes\" if the given context is useful in answering the question, and (2) \"no\" if the given context is not useful.\n",
      "Definition_change:  In this task, you are given a single tweet, a message and to answering the question. Your task is to be given out into two categories : ( 1 ) \" yes \" if the given context is useful in answering the question, and ( 2 ) \" no \" if the given context is not useful in\n",
      "Definition_native:  Given an abstract, generate a keyword (a noun phrase) that best describes the focus or contribution of the paper. Such keywords can be directly from the given abstract or outside it.\n",
      "Definition_change:  The more abstracts generate aword ( a noun phrase ) that best describes the focus or function of the paper. Such keywords can be generated from the more abstract to generate it.\n",
      "Definition_native:  Two analogies that relate items to the associated containers is given in the form \"A : B. C : ?\". \"A : B\" relates item A to its associated container B. Your task is to replace the question mark (?) with the appropriate container for the given item C, following the \"A : B\" relation.\n",
      "Definition_change:  Two analogies that relate items to the associated containers is given in the form \" A : B. C : B \". \" A : B \" connects item A to the associated container B. Your task is to replace the item mark ( C ) with the appropriate container for the given item C, following the \" A : B \" relation.\n",
      "Definition_native:  Given a real-life anecdote of a complex ethical situation, generate a suitable title that describes the main event/root cause of the situation. Imagine that the given text is a social media post, and you have to write the title of the post, so the users can decide to read the main text or not.\n",
      "Definition_change:  Imagine a real - life anecdote of a complex historical situation and generate a suitable text that describes the main event / root cause of the situation. Imagine that the given text is a social media post, and you have to read the title of the post, so the users can decide to read the main event or events.\n",
      "Definition_native:  Read the passage and find if the passage agrees, disagrees, or has a neutral stance on whether Global warming is caused by human activities. Answer only with keyword (a) agrees - if passage agrees with the target (b) disagrees - if passage disagrees with the target (c) neutral - if the given passage neither agrees nor disagrees with the target. You don't need to use external knowledge in this task, and you have to answer based on the given passage.\n",
      "Definition_change:  Read the passage and find if the passage agrees, agrees, or has a neutral opinion on whether Global warming is caused by these activities. Read only with keyword ( a ) agrees - if passage agrees with the target ( b ) disagrees - if passage disagrees with the target ( c ) neutral - if the given passage neither agrees nor disagrees with the target. You don't need to use external knowledge in this task, and you have to answer based on the given passage.\n",
      "Definition_native:  Generate an overlapping word between the given two sentences. When you find the overlapping words, they don't have to match exactly, e.g., \"survival\" and \"survive\" are valid overlapping words. Little words like \"the\" or \"of\" don't count! You must generate significant words which are not the stop words.\n",
      "Definition_change:  Generate an overlapping word between the given two sentences. When you find the overlapping words, they don't have to do exactly, e. g., \" survival \" and \" survive \" are the overlapping words. Little words like \" the \" or \" of \" don't count! \" must generate significant words which are not the stop words.\n",
      "Definition_native:  Two analogies that relate places/locations to the associated travel mode is given in the form \"A : B. C : ?\". \"A : B\" relates place A to travel mode B. Your task is to replace the question mark (?) with the appropriate travel mode for the given place C, following the \"A : B\" relation.\n",
      "Definition_change:  Two analogies to relate places / locations to the associated travel mode are given in the form \" A. B. C :? \". \" A : B \" relates place A to travel mode C. Your task is to replace the questionnaire (? ) with the appropriate travel mode for the given place C, following the \" C : B \" relation.\n",
      "Definition_native:  In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the numbers 0 (entailment), 1 (neutral), or 2(contradiction).\n",
      "Definition_change:  In your task, you must be given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree ( entailment ) / disagree ( contradiction ) with each other, or if this cannot be determined ( neutral ). Your answer must be in the form of the numbers 0 ( neutral ), 1 ( neutral ), or 2 ( contradiction ).\n",
      "Definition_native:  Given a paragraph about movies and a set of conversational questions and answers about the paragraph, say whether the passage contains sufficient information to answer the follow-up question. Say Yes if it is answerable; otherwise, say No. The paragraph has the prefix 'CONTEXT:'. Each conversation question has a prefix `Q:` followed by the answer prefix `A:`, and the follow-up question has a prefix `FOLLOWUP_Q:`.\n",
      "Definition_change:  Given a paragraph about movies, a set of of questions and answers about the paragraph, say whether the passage is sufficient information to answer the follow - up question. Say Yes if it is answerable ; otherwise, say No. The conversation has the prefix'CONTEXT :. The conversation question has a prefix Q : followed by the answer prefix A :, and the follow - up question has a prefix FOLLOWUP _ Q :.\n",
      "Definition_native:  In this task, you're given a question, along with a context passage. The passage will not have a direct answer to the question, but can include some information and a clue for the answer. Assuming you can only obtain information about one entity in the passage, your job is to determine whether information from the passage can be used to answer the question. Indicate your choice as `a` for Yes or `b` for No.\n",
      "Definition_change:  In this task, you're given a question, along with a context passage. The passage will not include a direct answer to the question, but can include some information and a clue for the answer. Assuming you can only obtain information about one entity in the passage, your job is to determine whether information from the passage can be used to answer the question.. your choice as a for Yes or b for No.\n",
      "Definition_native:  In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis, that is, it makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis, that is, it makes you much more likely to believe the hypothesis is true. Your task is to answer with 'strengthener' or 'weakener' if the update strengthens or weakens the hypothesis, respectively.\n",
      "Definition_change:  In this task, you are given a premise, a hypothesis, and a update. The premise sentence describes a real - world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might test or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis, that is, it makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis, that is, it makes you much more likely to believe the hypothesis is true. Your task is to answer questions'strengthener'and'weakener'if the update causes or weakens the hypothesis, respectively.\n",
      "Definition_native:  In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\".\n",
      "Definition_change:  In this task, you will be presented with a premise of a hypothesis sentence. Determine whether the hypothesis sentence entails ( implies ), contradicts ( states ), or is neutral with respect to the hypothesis sentence. The answer with \" Contradiction \", \" Question \", or \" Entailment \".\n",
      "Definition_native:  Two analogies that relate actions with their consequences are given in the form \"A : B. C : ?\". The phrase \"A : B\" relates action A to consequence B. Your task is to replace the question mark (?) with the appropriate consquence of the given action C, following the \"A : B\" relation. Your answer should be a single verb, without further explanation.\n",
      "Definition_change:  The analogies that are actions with their consequences are given in the form \" A : B. C :? \". The phrase \" A : B \" relates action A to consequence C. His task is to replace the question B (? ) with the appropriate consquence of the given action C, following the \" A : B \" relation. Your answer should be a single verb, without further explanation.\n",
      "Definition_native:  In this task you are given a story and a question regarding that story. You must judge whether the question is answerable based on the info given to you. Label the instances as \"Answerable\" or \"Not Answerable\" based on your judgment. the story and the question are separated by a new line character.\n",
      "Definition_change:  In this case you are given a story and a question regarding that story. You must judge whether the question is answerable based on the info given to you. Label the instances as \" Answerable \" or \" Not Answerable \" based on the basis, the story and the question are separated by a new line up.\n",
      "Definition_native:  In this task, you will use your knowledge about language (and common sense) to determine what element the marked number refers to. The numbers are marked with two underlines around them, like: _ number _. There are several possible answers, you'll need to choose the proper one. Carefully read the given text, pay special attention to the marked number, think about what (unwritten) information the marked number holds inside, choose the most adequate word(s) from the optional answers. If none of them seems right to you, there's also an option for other. If your answer is \"REFERENCE\", also write the reference entity, otherwise write the implicit option name. Options to choose from are:\n",
      "REFERENCE: Some object which is being mentioned in the text before or after the target number. The reference answer has a higher priority than any other. If both Reference and another answer are possible, prioritize the Reference.\n",
      "YEAR: Describing a calendric year\n",
      "AGE: Describing someone's age\n",
      "CURRENCY: Reference to some monetary value e.g dollar, euro etc.\n",
      "PEOPLE: Describing a single/plural persons\n",
      "TIME: Describing a time of the day. Usually you can add the word o'clock after those numbers.\n",
      "OTHER: Some other option, which isn't listed here.\n",
      "Definition_change:  In this task, you will use your knowledge about language ( and common sense ) to determine what element the marked number refers to. The numbers are marked with two underlines around them, like : the number _. There are several possible answers, you'll need to choose the proper one. Carefully read the given text, pay special attention to the marked number, think about what ( unwritten ) information the marked number holds inside, choose the most adequate word ( s ) from the optional answers. If none of them seems right to you, there's also an answer for other. If your answer is \" REFERENCE \", also write the reference entity, otherwise write the implicit option name. Options to choose from are : REFERENCE : Some object which is being mentioned in the text before or after the target number. The reference answer has a higher priority than any other. If both Reference and another answer are available, prioritize the Reference. YEAR : Describing a calendric year AGE : Describing someone's age CURRENCY : Reference to some monetary value e. g dollar, euro etc. PEOPLE : Describing a single / plural persons TIME : Describing a time of the day. Usually you can add the word o'clock after those numbers. TIME : Some other option, which isn't listed here.\n",
      "Definition_native:  You are given data in tabular format and you need to generate a passage with content in plain text format based on the information present in the table.\n",
      "Definition_change:  You are given data in this format and you are to generate a passage with content in plain text format based on the information in the text table.\n",
      "Definition_native:  You're given a fill-in-the-blank question where the answer is PersonX. You need to minimally change the given question so that the answer flips to PersonY. This task typically involves replacing one word i.e., the 'trigger word' with its antonym (e.g., changing from \"sympathetic\" to \"stern\"). You should not change any content in the given question beyond a word or two i.e. the trigger word/phrase. PersonX and PersonY should not be equally likely to fill the blank. For your question, PersonY should be a well-agreed answer to fill in the blank. Your generations should NOT contain potentially explicit, offensive, or adult content. Do not use the names of real people or generic names (e.g., Donald Trump, John Doe, etc.) in your question. Avoid repeating the same style or phrase in generating your modified question e.g. this task can be always solved using a simple negation i.e. by adding not, never, etc. Instead, try to increase the word diversity. Your question must contain at least 15 and at most 30 words. Your question must have at least 70% overlapping words with the given question. You must utilize the given context word while writing the question. Your question must contain only one blank. Make sure that PersonX and PersonY have the same gender. In your question, PersonX and PersonY should be used only ONCE and PersonX should appear earlier than PersonY. Although there are many correct answers, you only need to write one of them.\n",
      "Definition_change:  You're given a fill - in - the - blank question where the answer is PersonX. You need to minimally change the given question so that the answer is to PersonY. This task typically involves replacing one word i. e., the'trigger word'with an antonym ( e. g., changing from \" sympathetic \" to \" stern \" ). You should not change any content in the given question beyond a word or two i. e., trigger word / phrase. PersonX and PersonY should not be equally likely to fill the blank. For your question, PersonY should be a well - agreed answer to fill in the blank. Your generations should NOT contain potentially explicit, offensive, or adult content. Do not use the names of real people or personalbrities ( e. g., Donald Trump, John Doe, etc. ) in your question. Avoid repeating the same style or phrase in generating your modified question e. g. this task can be always solved using a simple rule i. e. by, not, never, etc. Instead, try to increase the word diversity. Your question must contain at least 15 and at most 30 words. Your question must have at least 70 % overlapping words with the given question. You must utilize the given context word while writing the question. Your question must contain only one blank. Make sure that PersonX and PersonY have the same gender. In your question, PersonX and PersonY should be used only ONCE and PersonX should appear earlier than PersonY. Although there are many correct answers, you only need to write one of them.\n",
      "Definition_native:  In this task, you have to generate the title of the recipe given its required ingredients and directions.\n",
      "Definition_change:  In this task, the is to generate the title of a data with its required names and directions.\n",
      "Definition_native:  In this task, you will be given two sentences separated by \", so\". You should decide whether the first sentence can be the cause of the second sentence. If you can see a possible causation, answer with \"plausible\", otherwise answer with \"not plausible\".\n",
      "Definition_change:  In this task, you will be given two sentences separated by \", so \". You should be that the first sentence to be the end of the second sentence. If you can see a possible causation, answer with \" plausible \", otherwise answer with \",ly \".\n",
      "Definition_native:  Read the passage and find the corresponding person for the given pronoun. The word between ** ** is the target pronoun.\n",
      "Definition_change:  Read the passage and find the corresponding person of the target pronoun. The word ( * * * * for the target pronoun.\n",
      "Definition_native:  In this task, you are given an abstract of article. Your task is to generate title for this article. Preferred titles are under thirty words.\n",
      "Definition_change:  In this task, you are given an amount of the.. This is to the title of this article. Preferred titles are under this article.\n",
      "Definition_native:  Given a text passage, you need to generate a suitable title as the output. The output title should be one of the words/phrases used in the passage and must be no longer than five words. \n",
      "Definition_change:  Given the text passage, we need to generate a suitable input as the output. The text passage should be one of the words / phrases used in the passage and must be much longer than the words.\n",
      "Definition_native:  Given a disfluent sentence, modify the sentence to it to its equivalent fluent form, preserving the meaning of the sentence.\n",
      "Definition_change:  Given the disfluent sentence to modify the sentence, it to be the the the to of the meaning of the sentence.\n",
      "Definition_native:  In this task, you are given triplets. Each triplet is in the form of [subject, predicate, object]. Your task is to generate proper sentence that utilizes these triples. The objective is to construct a sentence that (a) captures the facts specified in the triples and (b) is a well-formed sentence easily understandable by a human. All triple values need not be used directly in the sentence as long as the facts are adequately captured.\n",
      "Definition_change:  In this task, you are given triplets. Each triplet is in the form of [ subject, predicate, object ]. Your task is to generate proper sentence that utilizes these triples. The task is to construct a sentence that ( a ) captures the facts specified in the triples and ( b ) is a well - formed sentence easily understandable by a human. All triple values need not be used elsewhere in the sentence as long as the facts are not captured.\n",
      "Definition_native:  You need to answer a given question containing a blank (_). Your answer must be one of the two objects mentioned in the question, for example \"trophy\" and \"suitcase\". Your answer must not contain a word that is not present in the question. Please don't use articles (e.g., the, a) before the answer.\n",
      "Definition_change:  Please need to answer a given question containing a blank ( _ ). Your answer must be one of the two things mentioned in the question, for example \" home \" and \" suitcase \". Your answer must not contain a word that is not present in the question. Please don't use articles ( e. g., the, a ) before the answer.\n",
      "Definition_native:  In this task you are given a list of triplets of the form [subject, predicate, object] and the output should be a question based on the triplets but with the subject and/or object replaced with blanks (represented using two or more consecutive underscores). Triplet values encompassed in [*] are special tokens that can be replaced with synonyms. The objective is to construct a question in a manner that (a) captures the facts specified in at least one of the triplets, and (b) ideally contains a limited number of blanks such that it is a well-formed question that is easy to answer. A blank can represent a single word or a phrase.\n",
      "Definition_change:  For this task they are given a list of triplets of the form [ subject, predicate, object ] and the question should be a question based on the triplets but with the subject and / or subject replaced with blanks ( represented using two or more consecutive underscores ). Triplet values encompassed in [ * ] are special tokens that can be replaced with synonyms. The objective is to construct a question in a manner that ( a ) captures the facts specified in at least one of the triplets, and ( b ) also contains a limited number of blanks such that it is a well - formed question that is easy to answer. A blank can represent a single word or a phrase.\n",
      "Definition_native:  Compose a new way to ask the same question. The new question must be asking the exact same thing as the original question does. Without any other information, you should be able to tell that the original question and the new question are the same. Preserve bracketed phrases in your new question. You can change the rest of the question provided the above requirements are satisfied. The new question must have a natural, fluent formulation, as if it were composed by a native English speaker. You will be given three pieces of information to help you create better questions. Those are: \"Answer\": the answer to the question, e.g., \"Honolulu\". \"Answer Type\": the type of the answer, e.g., \"Location\". \"Auxiliary Information\" is a detailed description of some concepts mentioned in the question, if any.\n",
      "Definition_change:  Compose a new way to ask the same question. The new question must be asking the the same thing as the original question does. Without any other information, you should be able to tell that the original question and the new question are the same. Preserve bracketed phrases in your new question. You can change the rest of the question provided the above questions are satisfied. The new question must have a natural, fluent tone, as if it were composed by a native English speaker. You will be given three pieces of information to help you create better questions. Those are : \" Answer \" : the answer to the question, e. g., \" Honolulu \". \" Answer Type \" : the type of the answer, e. g., \" Location \". \" Additional Information \" is a detailed description of some concepts mentioned in the question, if any.\n",
      "Definition_native:  In this task, you're given a statement and three sentences as choices. Your job is to determine the neutral choice based on your inference from the statement and your commonsense knowledge. The neutral choice is a sentence that neither agrees nor disagrees with the statement. Indicate your answer as '1', '2', or '3', corresponding to the choice number of the selected sentence. If sentence X agrees with sentence Y, one's correctness follows from the other one. If sentence X disagrees with sentence Y, they can not be correct at the same time.\n",
      "Definition_change:  In this task, you're given a statement and three sentences as choices. Your job is to determine the neutral choice based on the inference from the statement and your commonsense knowledge. The neutral choice is a sentence that neither agrees nor agrees with the statement. Indicate your answer as'1 ','2 ', or'3 ', corresponding to the choice number of the selected sentence. If sentence X agrees with sentence Y, one's correctness varies from the other one. If sentence X disagrees with sentence Y, they can not be correct at the same time.\n",
      "Definition_native:  In this task you will be given a question and a passage. You need to determine if the answer to the question is contained in the passage. If the answer can be found in the passage you should output 'True'. If the answer cannot be found in the passage you should output 'False'.\n",
      "Definition_change:  In this task you must be given a question and a passage. You need to determine if the answer to the question is contained in the passage. If the answer can be found in the passage you should output'True '. If the answer cannot be found in the passage you should output'True '.\n",
      "Definition_native:  Read the passage and find the corresponding pronoun for the given name. The word between ** ** is the target name. The pronoun should be one of 'her', 'him', 'he', 'she' and 'his' with proper casing based on the position in the passage.\n",
      "Definition_change:  Read the passage and find the corresponding pronoun for the given name. The word between * * * * is the target name. The pronoun should be one of'her ','him ','her ','her'and'his'with proper casing based on the position in the passage.\n",
      "Definition_native:  In this task your given two statements. You must judge whether the second sentence is the cause or effect of the first one. Label the instances as \"cause\" or \"effect\" based on your judgment. The sentences are separated by a newline character.\n",
      "Definition_change:  In this case your given two statements. You must judge whether the second sentence is the cause or effect of the first sentence. Label the instances as \" cause \" and \" effect \" based on your language. The statements are separated by a single language.\n",
      "Definition_native:  Given a text passage, come up with an appropriate title for it. The title should accurately represent what the main focus of the passage is. The title of a passage may be present in the first few sentences of the passage and/or be referred to multiple times in the passage. The title should be 1-5 words long.\n",
      "Definition_change:  Given a text passage, come up with an appropriate title for it. The title should accurately represent what the text focus of the passage is. The title of the title should be present in the first few sentences of the passage and / or be referred to multiple times in the passage. The title should be 1 - 2 words long.\n",
      "Definition_native:  Two analogies that relate items to whether they are trash or treasure is given in the form \"A : B. C : ?\". Items marked as \"trash\" are considered to not have value and can be disposed, whereas those marked as \"treasure\" are considered valuable items that must be retained. \"A : \"B relates item A to whether it is trash or treasure, as specified by B. Your task is to replace the question mark (?) with either `trash` or `treasure` for the given item C, following the \"A : B\" relation.\n",
      "Definition_change:  Two analogies that relate items to whether they are trash or treasure is given in the form \" A : B. C :? \". Items marked as \" question \" are considered to not have value and can be disposed, whereas those marked as \" treasure \" are considered valuable items that must be retained. \" A : \" B relates item A to whether it is trash or treasure, as specified by B. Your task is to replace the question mark (? ) with the trash or treasure for the given item C, using the \" A : B \" mark.\n",
      "Definition_native:  In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\".\n",
      "Definition_change:  In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the premise entails ( implies ), contradicts ( opposes ), or is in in respect to the given premise sentence. Please answer with \" hypothesis \", \" hypothesis \", or \" Entailment \".\n",
      "Definition_native:  You have to predict the type of conversation sentence given as input. Your predictions can be one among: 'information' if the input statement states a piece of information, 'question' if the input statement asks for some information, 'directive' if the input sentence involves the management or guidance of operations, and 'commissive' when it constitutes a statement that commits the speaker to some future action.\n",
      "Definition_change:  You have to understand the type of conversation sentence given as input. Your predictions can be one among :'information'if the input statement states a piece of information,'information'if the input statement asks for some information,'directive'if the input sentence involves the management or guidance of operations, and'commissive'when it is a statement that commits the speaker to some future action.\n",
      "Definition_native:  In this task, you are given a premise and hypothesis. The task is to classify them into three categories: 'positive' if the hypothesis supports the premise, 'negated' if it opposes the premise, and 'neutral' if it neither supports nor opposes it.\n",
      "Definition_change:  In this task, you are to the premise and hypothesis. The task is to classify them into three categories :'positive'if the hypothesis supports the premise,'negative'if it opposes the premise, and'negative'if it neither supports nor opposes it.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (566) must match the size of tensor b (512) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/gujiashe/Tk-Instruct/tmp/transformers.ipynb Cell 20\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bacl.cis.temple.edu/home/gujiashe/Tk-Instruct/tmp/transformers.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m \u001b[39mimport\u001b[39;00m set_seed\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bacl.cis.temple.edu/home/gujiashe/Tk-Instruct/tmp/transformers.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m set_seed(\u001b[39m0\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bacl.cis.temple.edu/home/gujiashe/Tk-Instruct/tmp/transformers.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m raw_datasets \u001b[39m=\u001b[39m load_dataset(\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bacl.cis.temple.edu/home/gujiashe/Tk-Instruct/tmp/transformers.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39m../src/ni_dataset_crud.py\u001b[39;49m\u001b[39m\"\u001b[39;49m, \n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bacl.cis.temple.edu/home/gujiashe/Tk-Instruct/tmp/transformers.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m     data_dir\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m../data/splits/default\u001b[39;49m\u001b[39m'\u001b[39;49m, \n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bacl.cis.temple.edu/home/gujiashe/Tk-Instruct/tmp/transformers.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m     task_dir\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m../data/tasks\u001b[39;49m\u001b[39m'\u001b[39;49m, \n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bacl.cis.temple.edu/home/gujiashe/Tk-Instruct/tmp/transformers.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m     cache_dir\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m../cache/\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bacl.cis.temple.edu/home/gujiashe/Tk-Instruct/tmp/transformers.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m     max_num_instances_per_task\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bacl.cis.temple.edu/home/gujiashe/Tk-Instruct/tmp/transformers.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m     max_num_instances_per_eval_task\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bacl.cis.temple.edu/home/gujiashe/Tk-Instruct/tmp/transformers.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m     perturb_method\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mreplace_words\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bacl.cis.temple.edu/home/gujiashe/Tk-Instruct/tmp/transformers.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m     download_mode \u001b[39m=\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mreuse_cache_if_exists\u001b[39;49m\u001b[39m'\u001b[39;49m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bacl.cis.temple.edu/home/gujiashe/Tk-Instruct/tmp/transformers.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bacl.cis.temple.edu/home/gujiashe/Tk-Instruct/tmp/transformers.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mprint\u001b[39m(raw_datasets[\u001b[39m'\u001b[39m\u001b[39mvalidation\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m101\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mDefinition\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[0;32m~/.conda/envs/instruction/lib/python3.9/site-packages/datasets/load.py:1694\u001b[0m, in \u001b[0;36mload_dataset\u001b[0;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, ignore_verifications, keep_in_memory, save_infos, revision, use_auth_token, task, streaming, script_version, **config_kwargs)\u001b[0m\n\u001b[1;32m   1691\u001b[0m try_from_hf_gcs \u001b[39m=\u001b[39m path \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m _PACKAGED_DATASETS_MODULES\n\u001b[1;32m   1693\u001b[0m \u001b[39m# Download and prepare data\u001b[39;00m\n\u001b[0;32m-> 1694\u001b[0m builder_instance\u001b[39m.\u001b[39;49mdownload_and_prepare(\n\u001b[1;32m   1695\u001b[0m     download_config\u001b[39m=\u001b[39;49mdownload_config,\n\u001b[1;32m   1696\u001b[0m     download_mode\u001b[39m=\u001b[39;49mdownload_mode,\n\u001b[1;32m   1697\u001b[0m     ignore_verifications\u001b[39m=\u001b[39;49mignore_verifications,\n\u001b[1;32m   1698\u001b[0m     try_from_hf_gcs\u001b[39m=\u001b[39;49mtry_from_hf_gcs,\n\u001b[1;32m   1699\u001b[0m     use_auth_token\u001b[39m=\u001b[39;49muse_auth_token,\n\u001b[1;32m   1700\u001b[0m )\n\u001b[1;32m   1702\u001b[0m \u001b[39m# Build dataset for splits\u001b[39;00m\n\u001b[1;32m   1703\u001b[0m keep_in_memory \u001b[39m=\u001b[39m (\n\u001b[1;32m   1704\u001b[0m     keep_in_memory \u001b[39mif\u001b[39;00m keep_in_memory \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m is_small_dataset(builder_instance\u001b[39m.\u001b[39minfo\u001b[39m.\u001b[39mdataset_size)\n\u001b[1;32m   1705\u001b[0m )\n",
      "File \u001b[0;32m~/.conda/envs/instruction/lib/python3.9/site-packages/datasets/builder.py:595\u001b[0m, in \u001b[0;36mDatasetBuilder.download_and_prepare\u001b[0;34m(self, download_config, download_mode, ignore_verifications, try_from_hf_gcs, dl_manager, base_path, use_auth_token, **download_and_prepare_kwargs)\u001b[0m\n\u001b[1;32m    593\u001b[0m         logger\u001b[39m.\u001b[39mwarning(\u001b[39m\"\u001b[39m\u001b[39mHF google storage unreachable. Downloading and preparing it from source\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    594\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m downloaded_from_gcs:\n\u001b[0;32m--> 595\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_download_and_prepare(\n\u001b[1;32m    596\u001b[0m         dl_manager\u001b[39m=\u001b[39;49mdl_manager, verify_infos\u001b[39m=\u001b[39;49mverify_infos, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mdownload_and_prepare_kwargs\n\u001b[1;32m    597\u001b[0m     )\n\u001b[1;32m    598\u001b[0m \u001b[39m# Sync info\u001b[39;00m\n\u001b[1;32m    599\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minfo\u001b[39m.\u001b[39mdataset_size \u001b[39m=\u001b[39m \u001b[39msum\u001b[39m(split\u001b[39m.\u001b[39mnum_bytes \u001b[39mfor\u001b[39;00m split \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minfo\u001b[39m.\u001b[39msplits\u001b[39m.\u001b[39mvalues())\n",
      "File \u001b[0;32m~/.conda/envs/instruction/lib/python3.9/site-packages/datasets/builder.py:683\u001b[0m, in \u001b[0;36mDatasetBuilder._download_and_prepare\u001b[0;34m(self, dl_manager, verify_infos, **prepare_split_kwargs)\u001b[0m\n\u001b[1;32m    679\u001b[0m split_dict\u001b[39m.\u001b[39madd(split_generator\u001b[39m.\u001b[39msplit_info)\n\u001b[1;32m    681\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    682\u001b[0m     \u001b[39m# Prepare split will record examples associated to the split\u001b[39;00m\n\u001b[0;32m--> 683\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_prepare_split(split_generator, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mprepare_split_kwargs)\n\u001b[1;32m    684\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    685\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mOSError\u001b[39;00m(\n\u001b[1;32m    686\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCannot find data file. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    687\u001b[0m         \u001b[39m+\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmanual_download_instructions \u001b[39mor\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    688\u001b[0m         \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mOriginal error:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    689\u001b[0m         \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(e)\n\u001b[1;32m    690\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
      "File \u001b[0;32m~/.conda/envs/instruction/lib/python3.9/site-packages/datasets/builder.py:1075\u001b[0m, in \u001b[0;36mGeneratorBasedBuilder._prepare_split\u001b[0;34m(self, split_generator)\u001b[0m\n\u001b[1;32m   1067\u001b[0m \u001b[39mwith\u001b[39;00m ArrowWriter(\n\u001b[1;32m   1068\u001b[0m     features\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39minfo\u001b[39m.\u001b[39mfeatures,\n\u001b[1;32m   1069\u001b[0m     path\u001b[39m=\u001b[39mfpath,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1072\u001b[0m     check_duplicates\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m   1073\u001b[0m ) \u001b[39mas\u001b[39;00m writer:\n\u001b[1;32m   1074\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1075\u001b[0m         \u001b[39mfor\u001b[39;00m key, record \u001b[39min\u001b[39;00m utils\u001b[39m.\u001b[39mtqdm(\n\u001b[1;32m   1076\u001b[0m             generator,\n\u001b[1;32m   1077\u001b[0m             unit\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m examples\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1078\u001b[0m             total\u001b[39m=\u001b[39msplit_info\u001b[39m.\u001b[39mnum_examples,\n\u001b[1;32m   1079\u001b[0m             leave\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m   1080\u001b[0m             disable\u001b[39m=\u001b[39m\u001b[39mbool\u001b[39m(logging\u001b[39m.\u001b[39mget_verbosity() \u001b[39m==\u001b[39m logging\u001b[39m.\u001b[39mNOTSET),\n\u001b[1;32m   1081\u001b[0m         ):\n\u001b[1;32m   1082\u001b[0m             example \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minfo\u001b[39m.\u001b[39mfeatures\u001b[39m.\u001b[39mencode_example(record)\n\u001b[1;32m   1083\u001b[0m             writer\u001b[39m.\u001b[39mwrite(example, key)\n",
      "File \u001b[0;32m~/.conda/envs/instruction/lib/python3.9/site-packages/tqdm/notebook.py:258\u001b[0m, in \u001b[0;36mtqdm_notebook.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     it \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39m(tqdm_notebook, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__iter__\u001b[39m()\n\u001b[0;32m--> 258\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m it:\n\u001b[1;32m    259\u001b[0m         \u001b[39m# return super(tqdm...) will not catch exception\u001b[39;00m\n\u001b[1;32m    260\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[1;32m    261\u001b[0m \u001b[39m# NB: except ... [ as ...] breaks IPython async KeyboardInterrupt\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/instruction/lib/python3.9/site-packages/tqdm/std.py:1195\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1192\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[1;32m   1194\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1195\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[1;32m   1196\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[1;32m   1197\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1198\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/huggingface/modules/datasets_modules/datasets/ni_dataset_crud/87c02665c2a1f7d0bece2821b9c4eacff1cc435986764bf7dafcb7d4e1c2f7f7/ni_dataset_crud.py:184\u001b[0m, in \u001b[0;36mNaturalInstructions._generate_examples\u001b[0;34m(self, path, task_dir, max_num_instances_per_task, subset, perturb_method)\u001b[0m\n\u001b[1;32m    182\u001b[0m     Definition_crud \u001b[39m=\u001b[39m crud\u001b[39m.\u001b[39minsert_words(Definition, \u001b[39m10\u001b[39m)\n\u001b[1;32m    183\u001b[0m \u001b[39melif\u001b[39;00m perturb_method \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mreplace_words\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 184\u001b[0m     Definition_crud \u001b[39m=\u001b[39m crud\u001b[39m.\u001b[39;49mreplace_words(Definition, \u001b[39m10\u001b[39;49m)\n\u001b[1;32m    185\u001b[0m \u001b[39melif\u001b[39;00m perturb_method \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mshuffle_words\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    186\u001b[0m     Definition_crud \u001b[39m=\u001b[39m crud\u001b[39m.\u001b[39mshuffle_words(Definition)\n",
      "File \u001b[0;32m~/.cache/huggingface/modules/datasets_modules/datasets/ni_dataset_crud/87c02665c2a1f7d0bece2821b9c4eacff1cc435986764bf7dafcb7d4e1c2f7f7/ni_dataset_crud.py:312\u001b[0m, in \u001b[0;36mDataAugmentation.replace_words\u001b[0;34m(self, Definition, num_mask)\u001b[0m\n\u001b[1;32m    310\u001b[0m inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtokenizer(Definition, return_tensors\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    311\u001b[0m input_ids \u001b[39m=\u001b[39m inputs[\u001b[39m'\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m0\u001b[39m]\n\u001b[0;32m--> 312\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49minputs)\n\u001b[1;32m    313\u001b[0m predictions \u001b[39m=\u001b[39m outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    315\u001b[0m _, sorted_idx \u001b[39m=\u001b[39m predictions[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39msort(dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, descending\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/.conda/envs/instruction/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.conda/envs/instruction/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py:1343\u001b[0m, in \u001b[0;36mBertForMaskedLM.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1334\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1335\u001b[0m \u001b[39mlabels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1336\u001b[0m \u001b[39m    Labels for computing the masked language modeling loss. Indices should be in `[-100, 0, ...,\u001b[39;00m\n\u001b[1;32m   1337\u001b[0m \u001b[39m    config.vocab_size]` (see `input_ids` docstring) Tokens with indices set to `-100` are ignored (masked), the\u001b[39;00m\n\u001b[1;32m   1338\u001b[0m \u001b[39m    loss is only computed for the tokens with labels in `[0, ..., config.vocab_size]`\u001b[39;00m\n\u001b[1;32m   1339\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1341\u001b[0m return_dict \u001b[39m=\u001b[39m return_dict \u001b[39mif\u001b[39;00m return_dict \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1343\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbert(\n\u001b[1;32m   1344\u001b[0m     input_ids,\n\u001b[1;32m   1345\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m   1346\u001b[0m     token_type_ids\u001b[39m=\u001b[39;49mtoken_type_ids,\n\u001b[1;32m   1347\u001b[0m     position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[1;32m   1348\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m   1349\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[1;32m   1350\u001b[0m     encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[1;32m   1351\u001b[0m     encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_attention_mask,\n\u001b[1;32m   1352\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1353\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   1354\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   1355\u001b[0m )\n\u001b[1;32m   1357\u001b[0m sequence_output \u001b[39m=\u001b[39m outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m   1358\u001b[0m prediction_scores \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcls(sequence_output)\n",
      "File \u001b[0;32m~/.conda/envs/instruction/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.conda/envs/instruction/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py:989\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    982\u001b[0m \u001b[39m# Prepare head mask if needed\u001b[39;00m\n\u001b[1;32m    983\u001b[0m \u001b[39m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[1;32m    984\u001b[0m \u001b[39m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[1;32m    985\u001b[0m \u001b[39m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[1;32m    986\u001b[0m \u001b[39m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[1;32m    987\u001b[0m head_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_head_mask(head_mask, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m--> 989\u001b[0m embedding_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membeddings(\n\u001b[1;32m    990\u001b[0m     input_ids\u001b[39m=\u001b[39;49minput_ids,\n\u001b[1;32m    991\u001b[0m     position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[1;32m    992\u001b[0m     token_type_ids\u001b[39m=\u001b[39;49mtoken_type_ids,\n\u001b[1;32m    993\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[1;32m    994\u001b[0m     past_key_values_length\u001b[39m=\u001b[39;49mpast_key_values_length,\n\u001b[1;32m    995\u001b[0m )\n\u001b[1;32m    996\u001b[0m encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoder(\n\u001b[1;32m    997\u001b[0m     embedding_output,\n\u001b[1;32m    998\u001b[0m     attention_mask\u001b[39m=\u001b[39mextended_attention_mask,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1006\u001b[0m     return_dict\u001b[39m=\u001b[39mreturn_dict,\n\u001b[1;32m   1007\u001b[0m )\n\u001b[1;32m   1008\u001b[0m sequence_output \u001b[39m=\u001b[39m encoder_outputs[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/.conda/envs/instruction/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.conda/envs/instruction/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py:220\u001b[0m, in \u001b[0;36mBertEmbeddings.forward\u001b[0;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds, past_key_values_length)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mposition_embedding_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mabsolute\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    219\u001b[0m     position_embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mposition_embeddings(position_ids)\n\u001b[0;32m--> 220\u001b[0m     embeddings \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m position_embeddings\n\u001b[1;32m    221\u001b[0m embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mLayerNorm(embeddings)\n\u001b[1;32m    222\u001b[0m embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(embeddings)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (566) must match the size of tensor b (512) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, load_metric\n",
    "from transformers import set_seed\n",
    "set_seed(0)\n",
    "raw_datasets = load_dataset(\n",
    "    \"../src/ni_dataset_crud.py\", \n",
    "    data_dir='../data/splits/default', \n",
    "    task_dir='../data/tasks', \n",
    "    cache_dir='../cache/',\n",
    "    max_num_instances_per_task=100,\n",
    "    max_num_instances_per_eval_task=100,\n",
    "    perturb_method='replace_words',\n",
    "    download_mode = 'reuse_cache_if_exists'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "['In this task your given two statements in Estonian. You must judge whether the second sentence is the cause or effect of the first one. Label the instances as \"cause\" or \"effect\" based on your judgment. The sentences are separated by a newline character.']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import spacy\n",
    "import random\n",
    "from typing import Dict\n",
    "from tqdm import tqdm\n",
    "import transformers\n",
    "from transformers import BertTokenizer, BertModel, BertForMaskedLM\n",
    "\n",
    "transformers.logging.set_verbosity_error()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hell', '##o', 'world']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "tokenizer.tokenize('hello world')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataAugmentation:\n",
    "    def __init__(self):\n",
    "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "        self.model = BertForMaskedLM.from_pretrained('bert-base-multilingual-cased')\n",
    "        self.en = spacy.load('en_core_web_sm')\n",
    "        \n",
    "    @staticmethod\n",
    "    def connect_token_segments(tokens):\n",
    "        connected_tokens = []\n",
    "        for token in tokens:\n",
    "            if token.startswith(\"##\"):\n",
    "                connected_tokens[-1] = connected_tokens[-1] + token[2:]\n",
    "            else:\n",
    "                connected_tokens.append(token)\n",
    "        return connected_tokens\n",
    "\n",
    "\n",
    "    def delete_words(self, Definition, num=5):\n",
    "\n",
    "        tokens = self.tokenizer.tokenize(Definition)\n",
    "        tokens = self.connect_token_segments(tokens)\n",
    "\n",
    "        index = [i for i in range(len(tokens))]\n",
    "\n",
    "        deleted_index = random.sample(index, num)\n",
    "        deleted_index = set(deleted_index)\n",
    "\n",
    "        deleted_tokens = [tokens[i] for i in index if i not in deleted_index]\n",
    "        Definition_crud = self.tokenizer.convert_tokens_to_string(deleted_tokens)\n",
    "        return Definition_crud\n",
    "        \n",
    "    def delete_stopwords(self, Definition):\n",
    "        \n",
    "        tokens = self.tokenizer.tokenize(Definition)\n",
    "        tokens = self.connect_token_segments(tokens)\n",
    "\n",
    "        stopwords = self.en.Defaults.stop_words\n",
    "        deleted_tokens=[]\n",
    "        for token in tokens:\n",
    "            if token.lower() not in stopwords:\n",
    "                deleted_tokens.append(token)\n",
    "        Definition_crud =  self.tokenizer.convert_tokens_to_string(deleted_tokens)\n",
    "        return Definition_crud\n",
    "\n",
    "    def insert_words(self, Definition, num_mask=5):\n",
    "\n",
    "        tokens = self.tokenizer.tokenize(Definition)\n",
    "        tokens = self.connect_token_segments(tokens)\n",
    "\n",
    "        index = [i for i in range(len(tokens))]\n",
    "\n",
    "        index = random.sample(index, num_mask)\n",
    "\n",
    "        for i in index:\n",
    "            tokens.insert(i, '[MASK]')\n",
    "\n",
    "        if len(tokens)>512:\n",
    "            return Definition\n",
    "        \n",
    "        Definition = self.tokenizer.convert_tokens_to_string(tokens)\n",
    "        inputs = self.tokenizer(Definition, return_tensors='pt')\n",
    "        input_ids = inputs['input_ids'][0]\n",
    "        outputs = self.model(**inputs)\n",
    "        predictions = outputs[0]\n",
    "\n",
    "        _, sorted_idx = predictions[0].sort(dim=-1, descending=True)\n",
    "\n",
    "        predicted_index = [sorted_idx[i, 0].item() for i in range(0, len(predictions[0])-1)]\n",
    "        for x in range(1, len(predictions[0])-1):\n",
    "            if input_ids[x] == 103:\n",
    "                input_ids[x] = predicted_index[x]\n",
    "\n",
    "        return self.tokenizer.decode(input_ids, skip_special_tokens=True)\n",
    "\n",
    "    def replace_words(self, Definition, num_mask=5):\n",
    "\n",
    "        tokens = self.tokenizer.tokenize(Definition)\n",
    "        tokens = self.connect_token_segments(tokens)\n",
    "\n",
    "        index = [i for i in range(len(tokens))]\n",
    "\n",
    "        index = random.sample(index, num_mask)\n",
    "\n",
    "        for i in index:\n",
    "            tokens[i] = '[MASK]'\n",
    "\n",
    "        if len(tokens)>512:\n",
    "            return Definition\n",
    "        \n",
    "        Definition = self.tokenizer.convert_tokens_to_string(tokens)\n",
    "        inputs = self.tokenizer(Definition, return_tensors='pt')\n",
    "        input_ids = inputs['input_ids'][0]\n",
    "        outputs = self.model(**inputs)\n",
    "        predictions = outputs[0]\n",
    "\n",
    "        _, sorted_idx = predictions[0].sort(dim=-1, descending=True)\n",
    "\n",
    "        predicted_index = [sorted_idx[i, 0].item() for i in range(0, len(predictions[0])-1)]\n",
    "        for x in range(1, len(predictions[0])-1):\n",
    "            if input_ids[x] == 103:\n",
    "                input_ids[x] = predicted_index[x]\n",
    "\n",
    "        return self.tokenizer.decode(input_ids, skip_special_tokens=True)\n",
    "    \n",
    "    def shuffle_words(self, Definition):\n",
    "\n",
    "        tokens = self.tokenizer.tokenize(Definition)\n",
    "        tokens = self.connect_token_segments(tokens)\n",
    "\n",
    "        random.shuffle(tokens)\n",
    "        return self.tokenizer.convert_tokens_to_string(tokens)\n",
    "    \n",
    "    def shuffle_sentences(self, Definition):\n",
    "\n",
    "        doc = self.en(Definition)\n",
    "        sents = list(map(str, doc.sents))\n",
    "        random.shuffle(sents)\n",
    "        return \" \".join(sents)\n",
    "\n",
    "    def repeat_sentences(self, Definition, index = None):\n",
    "        doc = self.en(Definition)\n",
    "        sents = list(map(str, doc.sents))\n",
    "        if None == index:\n",
    "            index = random.randint(0, len(sents)-1)\n",
    "        sents = sents[:index] + [sents[index]] + sents[index:]\n",
    "        return \" \".join(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "such of abstract a paper of a an the key for generate . this paper paper Given title , conveys the focus that\n"
     ]
    }
   ],
   "source": [
    "data_augmentation = DataAugmentation()\n",
    "# print(data_augmentation.delete_words('Given an abstract of a paper, generate a title for this paper such that conveys the key focus of the paper.', 10))\n",
    "# print(data_augmentation.delete_stopwords('Given five abstract of a paper, generate a title for this paper such that conveys the key focus of the paper.'))\n",
    "# print(data_augmentation.insert_words('Given an abstract of a paper, generate a title for this paper such that conveys the key focus of the paper.', 2))\n",
    "# print(data_augmentation.replace_words('Given an abstract of a paper, generate a title for this paper such that conveys the key focus of the paper.', 2))\n",
    "# print(data_augmentation.shuffle_words('Given an abstract of a paper, generate a title for this paper such that conveys the key focus of the paper.'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      0  \\\n",
      "0  Original Instruction   \n",
      "1      delete_stopwords   \n",
      "2          delete_words   \n",
      "3          insert_words   \n",
      "4      repeat_sentences   \n",
      "5         replace_words   \n",
      "6     shuffle_sentences   \n",
      "7         shuffle_words   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         1  \n",
      "0                                                                                     You are given a sentence from a conversation between a human and a virtual assistant. Your task is to classify the sentence into one of the following five action categories - INFORM, INFORM_INTENT, OFFER, REQUEST, REQUEST_ALTS. If the sentence is about informing something, generate 'INFORM'. If it is about requesting something, generate 'REQUEST'. If the sentence mentions requesting an alternative option than the one provided, generate 'REQUEST_ALTS'. Similarly, generate 'OFFER' if the sentence is offering some information. If the sentence is about showing intent to do something, generate 'INFORM_INTENT'.  \n",
      "1                                                                                                                                                                                                                                                     given sentence conversation human virtual assistant. task classify sentence following action categories - INFORM, INFORM_INTENT, OFFER, REQUEST, REQUEST_ALTS. sentence informing something, generate 'INFORM'. requesting something, generate 'REQUEST'. sentence mentions requesting alternative option provided, generate 'REQUEST_ALTS'. Similarly, generate 'OFFER' sentence offering information. sentence showing intent something, generate 'INFORM_INTENT'.  \n",
      "2                                                                                                                          You are given a sentence from a conversation between a and a virtual assistant. Your task is to the sentence into one of the following five action categories - INFORM, INFORM_INTENT, OFFER, REQUEST, REQUEST_ALTS. If the sentence is about informing something, generate 'INFORM'. If it is about requesting something, generate 'REQUEST'. If the sentence mentions requesting an alternative option than the one generate 'REQUEST_ALTS'. Similarly, generate 'OFFER' the is offering some information. If the sentence is about showing intent to do something, generate 'INFORM_INTENT'.  \n",
      "3                                                                    You are given to a sentence from a conversation between a virtual human and a virtual assistant. Your task is to classify the sentence into one of the following five action categories - : INFORM, INFORM_INTENT, OFFER, , REQUEST, REQUEST_ALTS. If the sentence is about informing something, generate 'INFORM'. If it is about requesting something, generate 'REQUEST'. If the sentence mentions requesting an alternative option than the one provided, generate 'REQUEST_ALTS'. ( Similarly, generate 'OFFER' if the sentence is offering some information. If the sentence is about showing intent to do something, generate 'INFORM_INTENT'.  \n",
      "4  You are given a sentence from a conversation between a human and a virtual assistant. Your task is to classify the sentence into one of the following five action categories - INFORM, INFORM_INTENT, OFFER, REQUEST, REQUEST_ALTS. If the sentence is about informing something, generate 'INFORM'. If it is about requesting something, generate 'REQUEST'. If the sentence mentions requesting an alternative option than the one provided, generate 'REQUEST_ALTS'. Similarly, generate 'OFFER' if the sentence is offering some information. If the sentence is about showing intent to do something, generate 'INFORM_INTENT'. If the sentence is about showing intent to do something, generate 'INFORM_INTENT'.  \n",
      "5                                                                               You are given a sentence from a conversation between a human and a virtual assistant. Your task is to classify the sentence into one of the following five action categories - INFORM, INFORM _ INTENT, OFFER, REQUEST, REQUEST _ ALTS. If the sentence is about informing something, generate'INFORM '. If it is about requesting something, generate'REQUEST '. If the sentence mentions requesting an alternative option than the one provided, generate'REQUEST _ ALTS '. Similarly, generate'OFFER'if the sentence is offering some information. If the sentence is about showing intent to do something, generate'INFORM _ INTENT '.  \n",
      "6                                                                                     If the sentence is about informing something, generate 'INFORM'. If it is about requesting something, generate 'REQUEST'. Your task is to classify the sentence into one of the following five action categories - INFORM, INFORM_INTENT, OFFER, REQUEST, REQUEST_ALTS. If the sentence is about showing intent to do something, generate 'INFORM_INTENT'. If the sentence mentions requesting an alternative option than the one provided, generate 'REQUEST_ALTS'. Similarly, generate 'OFFER' if the sentence is offering some information. You are given a sentence from a conversation between a human and a virtual assistant.  \n",
      "7                                                                                     is a REQUEST, some five one option You If provided, is following If the 'OFFER' something, OFFER, from INFORM, the about the the sentence 'REQUEST'. If categories one task sentence Similarly, requesting REQUEST_ALTS. generate offering sentence 'REQUEST_ALTS'. than a and - requesting about of the if about human 'INFORM_INTENT'. action conversation showing a information. Your a assistant. something, an alternative into generate is is to classify to given between sentence something, sentence mentions INFORM_INTENT, are do generate virtual sentence If it generate informing is the 'INFORM'. intent generate the  \n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "original_instruction = \"You are given a sentence from a conversation between a human and a virtual assistant. Your task is to classify the sentence into one of the following five action categories - INFORM, INFORM_INTENT, OFFER, REQUEST, REQUEST_ALTS. If the sentence is about informing something, generate 'INFORM'. If it is about requesting something, generate 'REQUEST'. If the sentence mentions requesting an alternative option than the one provided, generate 'REQUEST_ALTS'. Similarly, generate 'OFFER' if the sentence is offering some information. If the sentence is about showing intent to do something, generate 'INFORM_INTENT'.\"\n",
    "\n",
    "data_augmentation = DataAugmentation()\n",
    "# data_crud= data_augmentation.repeat_sentences(original_instruction, index = 0)\n",
    "# print(data_crud)\n",
    "attrs = (getattr(data_augmentation, name) for name in dir(data_augmentation))\n",
    "methods = filter(inspect.ismethod, attrs)\n",
    "compares = [[\"Original Instruction\", original_instruction]]\n",
    "for method in methods:\n",
    "    if method.__name__ != '__init__':\n",
    "        compares.append([method.__name__, method(original_instruction)])\n",
    "\n",
    "df_compares = pd.DataFrame(compares)\n",
    "# print(df_compares.style.to_latex(hrules=True))\n",
    "print(df_compares)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bc2c0cd89e4ba02e191b1e7889aaaf3c8919053db7e24df61ffe975264e317e1"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
