{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['data_to_text', 'grammar_error_correction', 'title_generation',\n",
      "       'keyword_tagging', 'overlap_extraction', 'question_rewriting',\n",
      "       'eval_rougeL'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import collections\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "english_exp_names_1 = []\n",
    "english_exp_names_3 = ['english', 'english_stopword', 'english_delete_5', 'english_delete_10', \\\n",
    "        'english_insert_5', 'english_insert_10', \\\n",
    "        'english_replace_5', 'english_replace_10', \\\n",
    "        'english_repeat_sentences', 'english_shuffle_sentences', 'english_shuffle_words', 'english_shuffle_instruction']\n",
    "\n",
    "exact_match = collections.defaultdict(list)\n",
    "rougeL = collections.defaultdict(list)\n",
    "classifications = ['answerability_classification', 'cause_effect_classification', 'coreference_resolution', \\\n",
    "    'dialogue_act_recognition', 'word_analogy', 'textual_entailment']\n",
    "non_classifications = ['data_to_text', 'grammar_error_correction', 'title_generation',\\\n",
    "    'keyword_tagging', 'overlap_extraction', 'question_rewriting']\n",
    "for english_exp_name in english_exp_names_1:\n",
    "    metric_file = open('/home/gujiashe/Tk-Instruct/tk_outputs/output_{}/all_results.json'.format(english_exp_name), 'r')\n",
    "    metric = json.load(metric_file)\n",
    "\n",
    "\n",
    "    for classification in classifications:\n",
    "        exact_match[classification].append(metric['eval_exact_match_for_{}'.format(classification)])\n",
    "    exact_match['eval_exact_match'].append(metric['eval_exact_match'])\n",
    "    for non_classification in non_classifications:\n",
    "        rougeL[non_classification].append(metric['eval_rougeL_for_{}'.format(non_classification)])\n",
    "    rougeL['eval_rougeL'].append(metric['eval_rougeL'])\n",
    "\n",
    "metric_file = open('/home/gujiashe/Tk-Instruct/tk_outputs/output_{}/all_results.json'.format(\"english\"), 'r')\n",
    "metric = json.load(metric_file)\n",
    "metric_names = metric.keys()\n",
    "def create_dict(keys):\n",
    "    d = {}\n",
    "    for key in keys:\n",
    "        d[key] = []\n",
    "    return d    \n",
    "for english_exp_name in english_exp_names_3:\n",
    "    metric_samples = create_dict(metric_names)\n",
    "    metric_means = create_dict(metric_names)\n",
    "    metric_stds = create_dict(metric_names)\n",
    "    for index in [1, 2, 3]:\n",
    "        _english_exp_name = english_exp_name + \"_{}\".format(index)\n",
    "\n",
    "        metric_file = open('/home/gujiashe/Tk-Instruct/tk_outputs/output_{}/all_results.json'.format(_english_exp_name), 'r')\n",
    "        metric = json.load(metric_file)\n",
    "        for metric_name in metric_names:\n",
    "            metric_samples[metric_name].append(metric[metric_name])\n",
    "    \n",
    "    for metric_name in metric_names:\n",
    "        metric_means[metric_name] = round(np.mean(metric_samples[metric_name]), 1)\n",
    "    for metric_name in metric_names:\n",
    "        metric_stds[metric_name] = round(np.std(metric_samples[metric_name]), 1)\n",
    "\n",
    "    # metrics = metric_means\n",
    "\n",
    "    for classification in classifications:\n",
    "        metric_mean = metric_means['eval_exact_match_for_{}'.format(classification)]\n",
    "        metric_std = metric_stds['eval_exact_match_for_{}'.format(classification)]\n",
    "        exact_match[classification].append(str(metric_mean) + \"\\u00B1\" + str(metric_std))\n",
    "    \n",
    "    for non_classification in non_classifications:\n",
    "        metric_mean = metric_means['eval_rougeL_for_{}'.format(non_classification)]\n",
    "        metric_std = metric_stds['eval_rougeL_for_{}'.format(non_classification)]\n",
    "        rougeL[non_classification].append(str(metric_mean) + \"\\u00B1\" + str(metric_std))\n",
    "    exact_match['eval_exact_match'].append(str(metric_means['eval_exact_match']) + \"\\u00B1\" + str(metric_stds['eval_exact_match']))\n",
    "    rougeL['eval_rougeL'].append(str(metric_means['eval_rougeL']) + \"\\u00B1\" + str(metric_stds['eval_rougeL']))\n",
    "english_rougeL = pd.DataFrame(rougeL)\n",
    "english_rougeL.index = english_exp_names_1 + english_exp_names_3\n",
    "english_exact_match = pd.DataFrame(exact_match)\n",
    "english_exact_match.index = english_exp_names_1 + english_exp_names_3\n",
    "\n",
    "def generate_new_columns(columns):\n",
    "    new_columns = []\n",
    "    for c in columns:\n",
    "        new_column = []\n",
    "        for first in c.split('_'):\n",
    "            new_column.append(first[0].upper())\n",
    "        new_columns.append(\"\".join(new_column))\n",
    "    return new_columns\n",
    "print(english_rougeL.columns)\n",
    "english_exact_match.columns = generate_new_columns(english_exact_match.columns)\n",
    "english_rougeL.columns = generate_new_columns(english_rougeL.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['AC', 'CEC', 'CR', 'DAR', 'WA', 'TE', 'EEM'], dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_exact_match.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DTT</th>\n",
       "      <th>GEC</th>\n",
       "      <th>TG</th>\n",
       "      <th>KT</th>\n",
       "      <th>OE</th>\n",
       "      <th>QR</th>\n",
       "      <th>ER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>english</th>\n",
       "      <td>43.3±0.5</td>\n",
       "      <td>85.7±1.1</td>\n",
       "      <td>37.4±0.5</td>\n",
       "      <td>64.8±1.9</td>\n",
       "      <td>32.7±1.4</td>\n",
       "      <td>68.0±0.2</td>\n",
       "      <td>54.8±0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>english_stopword</th>\n",
       "      <td>43.8±0.4</td>\n",
       "      <td>85.2±0.5</td>\n",
       "      <td>37.2±0.3</td>\n",
       "      <td>63.6±0.3</td>\n",
       "      <td>34.2±1.0</td>\n",
       "      <td>68.0±0.3</td>\n",
       "      <td>53.8±0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>english_delete_5</th>\n",
       "      <td>42.2±0.3</td>\n",
       "      <td>84.1±0.7</td>\n",
       "      <td>37.2±0.3</td>\n",
       "      <td>64.2±1.2</td>\n",
       "      <td>37.4±1.4</td>\n",
       "      <td>67.4±0.2</td>\n",
       "      <td>53.7±0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>english_delete_10</th>\n",
       "      <td>42.2±0.5</td>\n",
       "      <td>85.0±2.0</td>\n",
       "      <td>36.8±0.2</td>\n",
       "      <td>64.0±1.0</td>\n",
       "      <td>34.4±1.8</td>\n",
       "      <td>67.5±0.0</td>\n",
       "      <td>53.6±0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>english_insert_5</th>\n",
       "      <td>41.8±0.4</td>\n",
       "      <td>85.3±0.8</td>\n",
       "      <td>37.2±0.2</td>\n",
       "      <td>61.1±2.6</td>\n",
       "      <td>38.5±2.5</td>\n",
       "      <td>67.5±0.5</td>\n",
       "      <td>54.0±0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>english_insert_10</th>\n",
       "      <td>42.3±0.5</td>\n",
       "      <td>86.6±0.4</td>\n",
       "      <td>37.0±0.2</td>\n",
       "      <td>65.8±1.2</td>\n",
       "      <td>36.7±1.9</td>\n",
       "      <td>67.3±0.3</td>\n",
       "      <td>53.8±0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>english_replace_5</th>\n",
       "      <td>42.7±0.3</td>\n",
       "      <td>85.1±1.1</td>\n",
       "      <td>37.1±0.4</td>\n",
       "      <td>63.5±2.3</td>\n",
       "      <td>35.0±1.2</td>\n",
       "      <td>67.8±0.2</td>\n",
       "      <td>54.0±0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>english_replace_10</th>\n",
       "      <td>42.5±0.4</td>\n",
       "      <td>84.0±1.5</td>\n",
       "      <td>36.9±0.4</td>\n",
       "      <td>65.6±1.6</td>\n",
       "      <td>36.0±3.3</td>\n",
       "      <td>68.2±0.5</td>\n",
       "      <td>53.6±0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>english_repeat_sentences</th>\n",
       "      <td>42.9±0.4</td>\n",
       "      <td>85.9±0.3</td>\n",
       "      <td>37.4±0.3</td>\n",
       "      <td>64.8±1.6</td>\n",
       "      <td>36.8±2.5</td>\n",
       "      <td>67.3±0.3</td>\n",
       "      <td>54.4±0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>english_shuffle_sentences</th>\n",
       "      <td>41.9±0.3</td>\n",
       "      <td>86.4±0.7</td>\n",
       "      <td>37.1±0.9</td>\n",
       "      <td>64.6±1.2</td>\n",
       "      <td>38.2±1.8</td>\n",
       "      <td>67.6±0.4</td>\n",
       "      <td>54.2±0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>english_shuffle_words</th>\n",
       "      <td>44.9±0.4</td>\n",
       "      <td>84.6±0.7</td>\n",
       "      <td>36.3±0.4</td>\n",
       "      <td>62.4±0.2</td>\n",
       "      <td>33.8±3.6</td>\n",
       "      <td>67.7±0.1</td>\n",
       "      <td>52.1±0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>english_shuffle_instruction</th>\n",
       "      <td>42.0±0.3</td>\n",
       "      <td>87.2±0.6</td>\n",
       "      <td>27.5±0.4</td>\n",
       "      <td>52.2±0.4</td>\n",
       "      <td>31.4±3.0</td>\n",
       "      <td>66.0±0.4</td>\n",
       "      <td>43.2±0.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  DTT       GEC        TG        KT        OE  \\\n",
       "english                      43.3±0.5  85.7±1.1  37.4±0.5  64.8±1.9  32.7±1.4   \n",
       "english_stopword             43.8±0.4  85.2±0.5  37.2±0.3  63.6±0.3  34.2±1.0   \n",
       "english_delete_5             42.2±0.3  84.1±0.7  37.2±0.3  64.2±1.2  37.4±1.4   \n",
       "english_delete_10            42.2±0.5  85.0±2.0  36.8±0.2  64.0±1.0  34.4±1.8   \n",
       "english_insert_5             41.8±0.4  85.3±0.8  37.2±0.2  61.1±2.6  38.5±2.5   \n",
       "english_insert_10            42.3±0.5  86.6±0.4  37.0±0.2  65.8±1.2  36.7±1.9   \n",
       "english_replace_5            42.7±0.3  85.1±1.1  37.1±0.4  63.5±2.3  35.0±1.2   \n",
       "english_replace_10           42.5±0.4  84.0±1.5  36.9±0.4  65.6±1.6  36.0±3.3   \n",
       "english_repeat_sentences     42.9±0.4  85.9±0.3  37.4±0.3  64.8±1.6  36.8±2.5   \n",
       "english_shuffle_sentences    41.9±0.3  86.4±0.7  37.1±0.9  64.6±1.2  38.2±1.8   \n",
       "english_shuffle_words        44.9±0.4  84.6±0.7  36.3±0.4  62.4±0.2  33.8±3.6   \n",
       "english_shuffle_instruction  42.0±0.3  87.2±0.6  27.5±0.4  52.2±0.4  31.4±3.0   \n",
       "\n",
       "                                   QR        ER  \n",
       "english                      68.0±0.2  54.8±0.4  \n",
       "english_stopword             68.0±0.3  53.8±0.4  \n",
       "english_delete_5             67.4±0.2  53.7±0.4  \n",
       "english_delete_10            67.5±0.0  53.6±0.3  \n",
       "english_insert_5             67.5±0.5  54.0±0.1  \n",
       "english_insert_10            67.3±0.3  53.8±0.0  \n",
       "english_replace_5            67.8±0.2  54.0±0.2  \n",
       "english_replace_10           68.2±0.5  53.6±0.6  \n",
       "english_repeat_sentences     67.3±0.3  54.4±0.2  \n",
       "english_shuffle_sentences    67.6±0.4  54.2±0.2  \n",
       "english_shuffle_words        67.7±0.1  52.1±0.3  \n",
       "english_shuffle_instruction  66.0±0.4  43.2±0.1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_rougeL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llllllll}\n",
      "\\toprule\n",
      "{} &        AC &       CEC &        CR &       DAR &        WA &        TE &       EEM \\\\\n",
      "\\midrule\n",
      "english                     &  63.6±1.2 &  48.2±3.0 &  48.1±0.9 &  57.0±1.2 &  51.8±0.4 &  46.6±0.5 &  36.9±0.5 \\\\\n",
      "english\\_stopword            &  63.2±0.6 &  49.0±0.5 &  49.1±2.2 &  49.9±1.7 &  50.5±1.9 &  44.5±0.6 &  36.1±0.5 \\\\\n",
      "english\\_delete\\_5            &  60.7±2.0 &  49.1±2.3 &  47.2±0.7 &  53.1±1.0 &  52.8±0.5 &  44.7±1.1 &  36.0±0.6 \\\\\n",
      "english\\_delete\\_10           &  61.1±2.0 &  50.7±1.2 &  49.5±1.3 &  52.9±4.5 &  50.8±1.3 &  44.0±1.4 &  36.0±0.4 \\\\\n",
      "english\\_insert\\_5            &  60.8±1.4 &  48.5±0.4 &  49.5±1.0 &  55.3±1.7 &  51.0±1.2 &  45.7±0.7 &  36.3±0.2 \\\\\n",
      "english\\_insert\\_10           &  60.4±1.4 &  48.7±1.3 &  47.5±0.9 &  56.6±0.9 &  52.5±1.6 &  44.6±0.5 &  36.2±0.2 \\\\\n",
      "english\\_replace\\_5           &  62.0±0.5 &  48.3±0.7 &  48.3±0.4 &  54.4±2.7 &  50.0±0.7 &  45.0±0.8 &  36.0±0.3 \\\\\n",
      "english\\_replace\\_10          &  60.3±0.7 &  49.2±1.5 &  47.7±1.0 &  50.0±0.9 &  51.6±1.9 &  43.9±1.6 &  35.7±0.5 \\\\\n",
      "english\\_repeat\\_sentences    &  61.4±0.5 &  48.0±0.9 &  48.4±0.9 &  53.7±3.3 &  51.1±1.2 &  48.5±1.1 &  36.8±0.3 \\\\\n",
      "english\\_shuffle\\_sentences   &  62.2±1.2 &  49.6±0.8 &  48.6±1.4 &  54.4±0.2 &  50.1±0.7 &  45.2±1.7 &  36.4±0.4 \\\\\n",
      "english\\_shuffle\\_words       &  59.4±1.8 &  46.5±0.9 &  46.7±0.8 &  49.7±2.2 &  50.5±2.0 &  41.5±0.4 &  34.3±0.3 \\\\\n",
      "english\\_shuffle\\_instruction &  53.3±1.4 &  45.9±1.1 &  41.1±1.1 &  33.8±1.1 &  38.2±1.0 &  28.3±1.0 &  28.1±0.1 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_29755/296510610.py:1: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  print(english_exact_match.to_latex())\n"
     ]
    }
   ],
   "source": [
    "print(english_exact_match.to_latex())\n",
    "# print(english_rougeL.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import collections\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "xlingual_exp_names_1 = []\n",
    "xlingual_exp_names_3 = ['xlingual', 'xlingual_stopword', 'xlingual_delete_5', 'xlingual_delete_10', \\\n",
    "        'xlingual_insert_5', 'xlingual_insert_10', \\\n",
    "        'xlingual_replace_5', 'xlingual_replace_10', \\\n",
    "        'xlingual_repeat_sentences', 'xlingual_shuffle_sentences', 'xlingual_shuffle_words', 'xlingual_shuffle_instruction']\n",
    "exact_match = collections.defaultdict(list)\n",
    "rougeL = collections.defaultdict(list)\n",
    "classifications = ['answerability_classification', 'cause_effect_classification', 'textual_entailment']\n",
    "non_classifications = ['title_generation']\n",
    "for xlingual_exp_name in xlingual_exp_names_1:\n",
    "    metric_file = open('/home/gujiashe/Tk-Instruct/tk_outputs/output_{}/all_results.json'.format(xlingual_exp_name), 'r')\n",
    "    metric = json.load(metric_file)\n",
    "\n",
    "\n",
    "    for classification in classifications:\n",
    "        exact_match[classification].append(metric['eval_exact_match_for_{}'.format(classification)])\n",
    "    exact_match['eval_exact_match'].append(metric['eval_exact_match'])\n",
    "    for non_classification in non_classifications:\n",
    "        rougeL[non_classification].append(metric['eval_rougeL_for_{}'.format(non_classification)])\n",
    "    rougeL['eval_rougeL'].append(metric['eval_rougeL'])\n",
    "\n",
    "metric_file = open('/home/gujiashe/Tk-Instruct/tk_outputs/output_{}/all_results.json'.format(\"xlingual\"), 'r')\n",
    "metric = json.load(metric_file)\n",
    "metric_names = metric.keys()\n",
    "def create_dict(keys):\n",
    "    d = {}\n",
    "    for key in keys:\n",
    "        d[key] = []\n",
    "    return d    \n",
    "for xlingual_exp_name in xlingual_exp_names_3:\n",
    "    metric_samples = create_dict(metric_names)\n",
    "    metric_means = create_dict(metric_names)\n",
    "    metric_stds = create_dict(metric_names)\n",
    "    for index in [1, 2, 3]:\n",
    "        _xlingual_exp_name = xlingual_exp_name + \"_{}\".format(index)\n",
    "\n",
    "        metric_file = open('/home/gujiashe/Tk-Instruct/tk_outputs/output_{}/all_results.json'.format(_xlingual_exp_name), 'r')\n",
    "        metric = json.load(metric_file)\n",
    "        for metric_name in metric_names:\n",
    "            metric_samples[metric_name].append(metric[metric_name])\n",
    "    for metric_name in metric_names:\n",
    "        metric_means[metric_name] = round(np.mean(metric_samples[metric_name]), 1)\n",
    "    for metric_name in metric_names:\n",
    "        metric_stds[metric_name] = round(np.std(metric_samples[metric_name]), 1)\n",
    "\n",
    "    # metrics = metric_means\n",
    "\n",
    "    for classification in classifications:\n",
    "        metric_mean = metric_means['eval_exact_match_for_{}'.format(classification)]\n",
    "        metric_std = metric_stds['eval_exact_match_for_{}'.format(classification)]\n",
    "        exact_match[classification].append(str(metric_mean) + \"\\u00B1\" + str(metric_std))\n",
    "    \n",
    "    for non_classification in non_classifications:\n",
    "        metric_mean = metric_means['eval_rougeL_for_{}'.format(non_classification)]\n",
    "        metric_std = metric_stds['eval_rougeL_for_{}'.format(non_classification)]\n",
    "        rougeL[non_classification].append(str(metric_mean) + \"\\u00B1\" + str(metric_std))\n",
    "    exact_match['eval_exact_match'].append(str(metric_means['eval_exact_match']) + \"\\u00B1\" + str(metric_stds['eval_exact_match']))\n",
    "    rougeL['eval_rougeL'].append(str(metric_means['eval_rougeL']) + \"\\u00B1\" + str(metric_stds['eval_rougeL']))\n",
    "xlingual_rougeL = pd.DataFrame(rougeL)\n",
    "xlingual_rougeL.index = xlingual_exp_names_1 + xlingual_exp_names_3\n",
    "xlingual_exact_match = pd.DataFrame(exact_match)\n",
    "xlingual_exact_match.index = xlingual_exp_names_1 + xlingual_exp_names_3\n",
    "\n",
    "\n",
    "def generate_new_columns(columns):\n",
    "    new_columns = []\n",
    "    for c in columns:\n",
    "        new_column = []\n",
    "        for first in c.split('_'):\n",
    "            new_column.append(first[0].upper())\n",
    "        new_columns.append(\"\".join(new_column))\n",
    "    return new_columns\n",
    "xlingual_exact_match.columns = generate_new_columns(xlingual_exact_match.columns)\n",
    "xlingual_rougeL.columns = generate_new_columns(xlingual_rougeL.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lllll}\n",
      "\\toprule\n",
      "{} &        AC &       CEC &        TE &       EEM \\\\\n",
      "\\midrule\n",
      "xlingual                     &  72.0±0.8 &  54.2±0.6 &  20.0±1.2 &  50.2±0.5 \\\\\n",
      "xlingual\\_stopword            &  69.7±1.9 &  54.8±0.2 &  19.0±1.4 &  50.6±0.1 \\\\\n",
      "xlingual\\_delete\\_5            &  74.0±1.4 &  55.0±0.5 &  18.0±2.5 &  50.9±0.5 \\\\\n",
      "xlingual\\_delete\\_10           &  73.0±2.9 &  54.6±0.6 &  21.0±1.9 &  50.7±0.5 \\\\\n",
      "xlingual\\_insert\\_5            &  70.3±5.2 &  54.4±0.6 &  18.4±1.7 &  50.3±0.4 \\\\\n",
      "xlingual\\_insert\\_10           &  69.3±4.1 &  55.7±0.3 &  19.6±0.6 &  51.4±0.3 \\\\\n",
      "xlingual\\_replace\\_5           &  69.3±4.1 &  54.2±1.3 &  20.8±0.3 &  50.2±1.0 \\\\\n",
      "xlingual\\_replace\\_10          &  67.0±7.9 &  54.2±0.3 &  17.4±0.8 &  49.9±0.1 \\\\\n",
      "xlingual\\_repeat\\_sentences    &  74.7±1.2 &  55.2±0.6 &  20.9±2.4 &  51.3±0.4 \\\\\n",
      "xlingual\\_shuffle\\_sentences   &  67.3±1.2 &  54.9±0.5 &  19.1±1.6 &  50.6±0.6 \\\\\n",
      "xlingual\\_shuffle\\_words       &  70.0±5.7 &  53.2±0.1 &  16.0±2.6 &  49.0±0.2 \\\\\n",
      "xlingual\\_shuffle\\_instruction &  40.0±2.9 &  52.6±0.4 &   5.3±0.7 &  46.6±0.5 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_35720/285899341.py:1: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  print(xlingual_exact_match.to_latex())\n"
     ]
    }
   ],
   "source": [
    "print(xlingual_exact_match.to_latex())\n",
    "# print(xlingual_rougeL.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {'english_exact_match': english_exact_match, 'english_rougeL': english_rougeL, \\\n",
    "    'xlingual_exact_match': xlingual_exact_match, 'xlingual_rougeL': xlingual_rougeL}\n",
    "for metric_name, metric_var in metrics.items():\n",
    "    metric_var.to_csv(metric_name+'_means.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import collections\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "english_exp_names_1 = []\n",
    "english_exp_names_3 = ['english_new_instruction']\n",
    "\n",
    "exact_match = collections.defaultdict(list)\n",
    "rougeL = collections.defaultdict(list)\n",
    "classifications = ['answerability_classification', 'cause_effect_classification', 'coreference_resolution', \\\n",
    "    'dialogue_act_recognition', 'word_analogy', 'textual_entailment']\n",
    "non_classifications = ['data_to_text', 'grammar_error_correction', 'title_generation',\\\n",
    "    'keyword_tagging', 'overlap_extraction', 'question_rewriting']\n",
    "for english_exp_name in english_exp_names_1:\n",
    "    metric_file = open('/home/gujiashe/Tk-Instruct/tk_outputs/output_{}/all_results.json'.format(english_exp_name), 'r')\n",
    "    metric = json.load(metric_file)\n",
    "\n",
    "\n",
    "    for classification in classifications:\n",
    "        exact_match[classification].append(metric['eval_exact_match_for_{}'.format(classification)])\n",
    "    exact_match['eval_exact_match'].append(metric['eval_exact_match'])\n",
    "    for non_classification in non_classifications:\n",
    "        rougeL[non_classification].append(metric['eval_rougeL_for_{}'.format(non_classification)])\n",
    "    rougeL['eval_rougeL'].append(metric['eval_rougeL'])\n",
    "\n",
    "metric_file = open('/home/gujiashe/Tk-Instruct/tk_outputs/output_{}/all_results.json'.format(\"english_original_instruction\"), 'r')\n",
    "metric = json.load(metric_file)\n",
    "metric_names = metric.keys()\n",
    "# print(metric)\n",
    "def create_dict(keys):\n",
    "    d = {}\n",
    "    for key in keys:\n",
    "        d[key] = []\n",
    "    return d    \n",
    "for english_exp_name in english_exp_names_3:\n",
    "    metric_samples = create_dict(metric_names)\n",
    "    metric_means = create_dict(metric_names)\n",
    "    metric_stds = create_dict(metric_names)\n",
    "    for index in [1, 2, 3]:\n",
    "        _english_exp_name = english_exp_name + \"_{}\".format(index)\n",
    "\n",
    "        metric_file = open('/home/gujiashe/Tk-Instruct/tk_outputs/output_{}/all_results.json'.format(_english_exp_name), 'r')\n",
    "        metric = json.load(metric_file)\n",
    "        for metric_name in metric:\n",
    "            if metric_name.endswith(f'_new_{index}'):\n",
    "                metric_name_pruned = metric_name.replace(f'_new_{index}', '')\n",
    "            else:\n",
    "                metric_name_pruned = metric_name\n",
    "            metric_samples[metric_name_pruned].append(metric[metric_name])\n",
    "    \n",
    "    for metric_name in metric_names:\n",
    "        metric_means[metric_name] = round(np.mean(metric_samples[metric_name]), 1)\n",
    "    for metric_name in metric_names:\n",
    "        metric_stds[metric_name] = round(np.std(metric_samples[metric_name]), 1)\n",
    "\n",
    "    # metrics = metric_means\n",
    "\n",
    "    for classification in classifications:\n",
    "        metric_mean = metric_means['eval_exact_match_for_{}'.format(classification)]\n",
    "        metric_std = metric_stds['eval_exact_match_for_{}'.format(classification)]\n",
    "        exact_match[classification].append(str(metric_mean) + \"\\u00B1\" + str(metric_std))\n",
    "    \n",
    "    for non_classification in non_classifications:\n",
    "        metric_mean = metric_means['eval_rougeL_for_{}'.format(non_classification)]\n",
    "        metric_std = metric_stds['eval_rougeL_for_{}'.format(non_classification)]\n",
    "        rougeL[non_classification].append(str(metric_mean) + \"\\u00B1\" + str(metric_std))\n",
    "    exact_match['eval_exact_match'].append(str(metric_means['eval_exact_match']) + \"\\u00B1\" + str(metric_stds['eval_exact_match']))\n",
    "    rougeL['eval_rougeL'].append(str(metric_means['eval_rougeL']) + \"\\u00B1\" + str(metric_stds['eval_rougeL']))\n",
    "english_rougeL = pd.DataFrame(rougeL)\n",
    "english_rougeL.index = english_exp_names_1 + english_exp_names_3\n",
    "english_exact_match = pd.DataFrame(exact_match)\n",
    "english_exact_match.index = english_exp_names_1 + english_exp_names_3\n",
    "\n",
    "def generate_new_columns(columns):\n",
    "    new_columns = []\n",
    "    for c in columns:\n",
    "        new_column = []\n",
    "        for first in c.split('_'):\n",
    "            new_column.append(first[0].upper())\n",
    "        new_columns.append(\"\".join(new_column))\n",
    "    return new_columns\n",
    "english_exact_match.columns = generate_new_columns(english_exact_match.columns)\n",
    "english_rougeL.columns = generate_new_columns(english_rougeL.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llllllll}\n",
      "\\toprule\n",
      "{} &       DTT &       GEC &        TG &        KT &        OE &        QR &        ER \\\\\n",
      "\\midrule\n",
      "english\\_new\\_instruction &  44.2±0.3 &  84.3±0.3 &  24.6±0.2 &  72.0±0.6 &  32.7±0.1 &  81.3±0.2 &  58.0±0.5 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_35720/1850941337.py:2: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  print(english_rougeL.to_latex())\n"
     ]
    }
   ],
   "source": [
    "# print(english_exact_match.to_latex())\n",
    "print(english_rougeL.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AC</th>\n",
       "      <th>CEC</th>\n",
       "      <th>CR</th>\n",
       "      <th>DAR</th>\n",
       "      <th>WA</th>\n",
       "      <th>TE</th>\n",
       "      <th>EEM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>english_new_instruction</th>\n",
       "      <td>67.3±1.0</td>\n",
       "      <td>69.3±0.2</td>\n",
       "      <td>56.8±1.6</td>\n",
       "      <td>43.3±2.7</td>\n",
       "      <td>43.2±1.9</td>\n",
       "      <td>52.7±5.8</td>\n",
       "      <td>37.1±0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               AC       CEC        CR       DAR        WA  \\\n",
       "english_new_instruction  67.3±1.0  69.3±0.2  56.8±1.6  43.3±2.7  43.2±1.9   \n",
       "\n",
       "                               TE       EEM  \n",
       "english_new_instruction  52.7±5.8  37.1±0.5  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_exact_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DTT</th>\n",
       "      <th>GEC</th>\n",
       "      <th>TG</th>\n",
       "      <th>KT</th>\n",
       "      <th>OE</th>\n",
       "      <th>QR</th>\n",
       "      <th>ER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>english_new_instruction</th>\n",
       "      <td>44.2±0.3</td>\n",
       "      <td>84.3±0.3</td>\n",
       "      <td>24.6±0.2</td>\n",
       "      <td>72.0±0.6</td>\n",
       "      <td>32.7±0.1</td>\n",
       "      <td>81.3±0.2</td>\n",
       "      <td>58.0±0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              DTT       GEC        TG        KT        OE  \\\n",
       "english_new_instruction  44.2±0.3  84.3±0.3  24.6±0.2  72.0±0.6  32.7±0.1   \n",
       "\n",
       "                               QR        ER  \n",
       "english_new_instruction  81.3±0.2  58.0±0.5  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_rougeL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test tk_instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a am student I'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "def random_shuffle(Definition):\n",
    "\n",
    "    token_list = Definition.split()\n",
    "    random.shuffle(token_list)\n",
    "    return \" \".join(token_list)\n",
    "random_shuffle(\"I am a student\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"allenai/tk-instruct-3b-def\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"allenai/tk-instruct-3b-def\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \n"
     ]
    }
   ],
   "source": [
    "input_ids = tokenizer.encode(\n",
    "        # \"Definition: return the currency of the country. Now complete the following example - Input: China. Output:\", \n",
    "        \"فتوسنتز فرایندی زیست‌شیمیایی است که در آن، انرژی نورانی خورشید توسط گیاهان و برخی از باکتری‌ها به انرژی شیمیایی ذخیره‌شده در مواد غذایی آن‌ها تبدیل می‌شود. کمابیش همهٔ جانداران روی زمین به آن وابسته‌اند. در عمل فتوسنتز، اندام‌هایی مانند برگ که دارای سبزینه هستند، کربن دی‌اکسید، آب و نور را جذب کرده و به کلروپلاست می‌رسانند. طی واکنش‌هایی که درون کلروپلاست انجام می‌گیرد، این مواد به اکسیژن و کربوهیدرات‌ها تبدیل می‌شوند. همه اکسیژن کنونی موجود بر روی زمین، فراوردهٔ فتوسنتز است. برخی از کربوهیدرات‌های مهم تولیدشده مانند گلوکز، می‌توانند به دیگر مواد آلی، لیپیدها، نشاسته، سلولز و پروتئین تبدیل شوند که برای تبدیل‌شدن به پروتئین، نیاز به نیتروژن دارند. ژان باپتیست ون هلمونت، یکی از نخستین آزمایش‌های مربوط به فتوسنتز را انجام داد. همه بخش‌های سبزرنگ گیاه، قادر به انجام عمل فتوسنتز هستند. مادهٔ سبز موجود در گیاهان که سبزینه یا کلروفیل نام دارد، آغازکنندهٔ واکنش‌های فتوسنتز است. فتوسنتز در اندام‌هایی که فاقد سبزینه هستند، انجام نمی‌گیرد.\",\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "output = model.generate(input_ids, max_length=10)\n",
    "output = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load ni_dataset_crud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-ef21323b704ac40a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset natural_instructions/default to ../cache/natural_instructions/default-ef21323b704ac40a/2.0.0/3cc8a767ebfc2ec331ee88376c2925a8f55abffc944bdfeacb4be90f468c4b97...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38265feb2bf348a397cb901ce072dbe8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a444481b55a7415fa9587a90326450ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a3686ca4f574496aff4f29e8b7467c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset natural_instructions downloaded and prepared to ../cache/natural_instructions/default-ef21323b704ac40a/2.0.0/3cc8a767ebfc2ec331ee88376c2925a8f55abffc944bdfeacb4be90f468c4b97. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3f1f81c9ca94bde8c1b66b3d3853799",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Task': 'translation_en-es_0', 'Contributors': 'instruction_induction', 'Source': ['instruction_induction'], 'URL': ['instruction_induction'], 'Categories': ['instruction_induction'], 'Reasoning': ['instruction_induction'], 'Definition': ['Translate to Spanish'], 'Positive Examples': [], 'Negative Examples': [], 'Input_language': ['English'], 'Output_language': ['English'], 'Instruction_language': ['English'], 'Domains': ['instruction_induction'], 'Instance': {'input': 'ile', 'output': ['montón']}}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, load_metric\n",
    "from transformers import set_seed\n",
    "set_seed(0)\n",
    "raw_datasets = load_dataset(\n",
    "    \"../src/induction_dataset.py\", \n",
    "    data_dir='../induction_data/', \n",
    "    task_dir='../induction_data/tasks/', \n",
    "    cache_dir='../cache/',\n",
    "    max_num_instances_per_task=100,\n",
    "    max_num_instances_per_eval_task=100,\n",
    "    download_mode = 'reuse_cache_if_exists'\n",
    ")\n",
    "print(raw_datasets['test'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-8e82d9b055b27d6b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset natural_instructions/default (download: Unknown size, generated: 56.00 MiB, post-processed: Unknown size, total: 56.00 MiB) to /home/gujiashe/.cache/huggingface/datasets/natural_instructions/default-8e82d9b055b27d6b/2.0.0/c0040095172c0d76abd173b8640d8a5c5293cbc538c41e16bb88bdb4d0bb6a46...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b66a609439b14163a285c7f230954c96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "069571ce015b49278564eca2ec2651db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ba1a42a01354234a931018339445075",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset natural_instructions downloaded and prepared to /home/gujiashe/.cache/huggingface/datasets/natural_instructions/default-8e82d9b055b27d6b/2.0.0/c0040095172c0d76abd173b8640d8a5c5293cbc538c41e16bb88bdb4d0bb6a46. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "398280171d824d2e9d73a2577872a3a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Please fill out the bank (_) in the given text with an accurate pronoun regarding the target name between  ** **. The generated word should be a case-sensitive pronoun that matches its position in the text. You can choose from the following pronouns: 'her', 'him', 'he', 'she', and 'his'. \"]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, load_metric\n",
    "from transformers import set_seed\n",
    "set_seed(0)\n",
    "raw_datasets = load_dataset(\n",
    "    \"../src/ni_dataset.py\", \n",
    "    data_dir='../data/splits/default', \n",
    "    task_dir='../data/tasks', \n",
    "    # cache_dir='../cache/',\n",
    "    max_num_instances_per_task=100,\n",
    "    max_num_instances_per_eval_task=100,\n",
    "    # download_mode = 'reuse_cache_if_exists'\n",
    "    download_mode=\"force_redownload\"\n",
    ")\n",
    "print(raw_datasets['validation'][101]['Definition'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Read the passage and find the corresponding pronoun for the given name. The pronoun should match the given blank(_). The word between ** ** is the target name. The pronoun should be one of 'her', 'him', 'he', 'she' and 'his' with proper casing based on the position in the passage.\"]\n"
     ]
    }
   ],
   "source": [
    "print(raw_datasets['test'][101]['Definition'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, load_metric\n",
    "from transformers import set_seed\n",
    "set_seed(0)\n",
    "raw_datasets = load_dataset(\n",
    "    \"../src/ni_dataset_crud.py\", \n",
    "    data_dir='../data/splits/default', \n",
    "    task_dir='../data/tasks', \n",
    "    cache_dir='../cache/',\n",
    "    max_num_instances_per_task=100,\n",
    "    max_num_instances_per_eval_task=100,\n",
    "    download_mode = 'reuse_cache_if_exists'\n",
    ")\n",
    "print(raw_datasets['validation'][101]['Definition'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "['In this task your given two statements in Estonian. You must judge whether the second sentence is the cause or effect of the first one. Label the instances as \"cause\" or \"effect\" based on your judgment. The sentences are separated by a newline character.']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import spacy\n",
    "import random\n",
    "from typing import Dict\n",
    "from tqdm import tqdm\n",
    "import transformers\n",
    "from transformers import BertTokenizer, BertModel, BertForMaskedLM\n",
    "\n",
    "transformers.logging.set_verbosity_error()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataAugmentation:\n",
    "    def __init__(self):\n",
    "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "        self.model = BertForMaskedLM.from_pretrained('bert-base-multilingual-cased')\n",
    "        self.en = spacy.load('en_core_web_sm')\n",
    "        \n",
    "\n",
    "    def delete_num(self, Definition, num=5):\n",
    "\n",
    "        splited_definition = Definition.split()\n",
    "        index = [i for i in range(len(splited_definition))]\n",
    "        index = random.sample(index, len(splited_definition)-num)\n",
    "        index.sort()\n",
    "        Definition_crud = \" \".join([splited_definition[i] for i in index])\n",
    "        return Definition_crud\n",
    "        \n",
    "    def delete_stopwords(self, Definition):\n",
    "\n",
    "        #loading the english language small model of spacy\n",
    "        \n",
    "        stopwords = self.en.Defaults.stop_words\n",
    "        lst=[]\n",
    "        for token in Definition.split():\n",
    "            if token.lower() not in stopwords:    #checking whether the word is not \n",
    "                lst.append(token)                    #present in the stopword list.\n",
    "        Definition_crud = \" \".join(lst)     \n",
    "        return Definition_crud\n",
    "\n",
    "    def insert_mask(self, Definition, num_mask=5):\n",
    "\n",
    "        token_list = Definition.split()\n",
    "\n",
    "\n",
    "        num = 0\n",
    "        while num < num_mask:\n",
    "            num += 1\n",
    "            insert_position = random.randint(1, len(token_list) - 1)\n",
    "            token_list.insert(insert_position, '[MASK]')\n",
    "    \n",
    "\n",
    "        input_txt = ' '.join(token_list)\n",
    "\n",
    "        inputs = self.tokenizer(input_txt, return_tensors='pt')\n",
    "\n",
    "        \n",
    "        input_ids = inputs['input_ids'][0].numpy()\n",
    "        if input_ids.shape[0]>512:\n",
    "            return Definition\n",
    "        outputs = self.model(**inputs)\n",
    "        predictions = outputs[0]\n",
    "\n",
    "        _, sorted_idx = predictions[0].sort(dim=-1, descending=True)\n",
    "        \n",
    "        for k in range(1):\n",
    "            predicted_index = [sorted_idx[i, k].item() for i in range(0, len(predictions[0])-1)]\n",
    "            predicted_token = []\n",
    "            for x in range(1, len(predictions[0])-1):\n",
    "                if input_ids[x] == 103:\n",
    "                    predicted_token.append(self.tokenizer.convert_ids_to_tokens([predicted_index[x]])[0])\n",
    "        copy_token = predicted_token.copy()\n",
    "        token_list_copy = token_list.copy()\n",
    "        for i, token in enumerate(token_list):\n",
    "            if token == '[MASK]':\n",
    "                if len(predicted_token)==0:\n",
    "                    print(Definition)\n",
    "                    print(token_list_copy)\n",
    "                    print(copy_token)\n",
    "                token_list[i] = predicted_token.pop(0)\n",
    "        final_tokens = []\n",
    "        for token in token_list:\n",
    "            if token.startswith('##'):\n",
    "                final_tokens[-1] = final_tokens[-1] + token[2:]\n",
    "            else:\n",
    "                final_tokens.append(token)\n",
    "\n",
    "        return \" \".join(final_tokens)\n",
    "\n",
    "    def replace_num(self, Definition, num_mask=5):\n",
    "\n",
    "        inputs = self.tokenizer(Definition, return_tensors='pt')\n",
    "        input_ids = inputs['input_ids'][0]\n",
    "\n",
    "        index = [i for i in range(len(input_ids))]\n",
    "\n",
    "        index = random.sample(index, num_mask)\n",
    "\n",
    "        index.sort()\n",
    "        for i in index:\n",
    "            input_ids[i] = 103\n",
    "\n",
    "\n",
    "        if len(input_ids)>512:\n",
    "            return Definition\n",
    "        inputs['input_ids'][0] = input_ids\n",
    "        outputs = self.model(**inputs)\n",
    "        predictions = outputs[0]\n",
    "\n",
    "        _, sorted_idx = predictions[0].sort(dim=-1, descending=True)\n",
    "\n",
    "        for k in range(1):\n",
    "            predicted_index = [sorted_idx[i, k].item() for i in range(0, len(predictions[0])-1)]\n",
    "            for x in range(1, len(predictions[0])-1):\n",
    "                if input_ids[x] == 103:\n",
    "                    input_ids[x] = predicted_index[x]\n",
    "\n",
    "        return self.tokenizer.decode(input_ids[1: -1])\n",
    "    \n",
    "    def shuffle_words(self, Definition):\n",
    "\n",
    "        token_list = Definition.split()\n",
    "        random.shuffle(token_list)\n",
    "        return \" \".join(token_list)\n",
    "    \n",
    "    def shuffle_sentences(self, Definition):\n",
    "\n",
    "        doc = self.en(Definition)\n",
    "        sents = list(map(str, doc.sents))\n",
    "        random.shuffle(sents)\n",
    "        return \" \".join(sents)\n",
    "\n",
    "    def repeat_sentences(self, Definition, index = None):\n",
    "        doc = self.en(Definition)\n",
    "        sents = list(map(str, doc.sents))\n",
    "        if None == index:\n",
    "            index = random.randint(0, len(sents)-1)\n",
    "        sents = sents[:index] + [sents[index]] + sents[index:]\n",
    "        return \" \".join(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given an incorrect English sentence. Given an incorrect English sentence. Your task is to correct the input sentence and write out his correct form.\n"
     ]
    }
   ],
   "source": [
    "original_instruction = \"Given an incorrect English sentence. Your task is to correct the input sentence and write out his correct form.\"\n",
    "\n",
    "data_augmentation = DataAugmentation()\n",
    "data_crud= data_augmentation.repeat_sentences(original_instruction, index = 0)\n",
    "print(data_crud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "attrs = (getattr(data_augmentation, name) for name in dir(data_augmentation))\n",
    "methods = filter(inspect.ismethod, attrs)\n",
    "compares = [[\"Original Instruction\", original_instruction]]\n",
    "for method in methods:\n",
    "    if method.__name__ != '__init__':\n",
    "        compares.append([method.__name__, method(original_instruction)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Perturbed Instruction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Method</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Original Instruction</th>\n",
       "      <td>Given an incorrect English sentence. Your task...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>delete_num</th>\n",
       "      <td>Given an English sentence. Your task is to cor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>delete_stopwords</th>\n",
       "      <td>Given incorrect English sentence. task correct...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>insert_mask</th>\n",
       "      <td>Given is an incorrect English - input sentence...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>repeat_sentences</th>\n",
       "      <td>Given an incorrect English sentence. Your task...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>replace_num</th>\n",
       "      <td>Given an incorrect English translation. Your t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shuffle_sentences</th>\n",
       "      <td>Your task is to correct the input sentence and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shuffle_words</th>\n",
       "      <td>is correct form. Given write sentence. his You...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Perturbed Instruction\n",
       "Method                                                                 \n",
       "Original Instruction  Given an incorrect English sentence. Your task...\n",
       "delete_num            Given an English sentence. Your task is to cor...\n",
       "delete_stopwords      Given incorrect English sentence. task correct...\n",
       "insert_mask           Given is an incorrect English - input sentence...\n",
       "repeat_sentences      Given an incorrect English sentence. Your task...\n",
       "replace_num           Given an incorrect English translation. Your t...\n",
       "shuffle_sentences     Your task is to correct the input sentence and...\n",
       "shuffle_words         is correct form. Given write sentence. his You..."
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_compares = pd.DataFrame(compares)\n",
    "df_compares.columns = [\"Method\", \"Perturbed Instruction\"]\n",
    "df_compares.index = df_compares[\"Method\"]\n",
    "\n",
    "df_compares.iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{ll}\n",
      "\\toprule\n",
      " & Perturbed Instruction \\\\\n",
      "Method &  \\\\\n",
      "\\midrule\n",
      "Original Instruction & Given an incorrect English sentence. Your task is to correct the input sentence and write out his correct form. \\\\\n",
      "delete_num & Given an English sentence. Your task is to correct the input sentence his correct \\\\\n",
      "delete_stopwords & Given incorrect English sentence. task correct input sentence write correct form. \\\\\n",
      "insert_mask & Given is an incorrect English - input sentence. \" Your task is to correct the input sentence and to write out his correct form. \\\\\n",
      "repeat_sentences & Given an incorrect English sentence. Your task is to correct the input sentence and write out his correct form. Your task is to correct the input sentence and write out his correct form. \\\\\n",
      "replace_num & Given an incorrect English translation. Your task is to read the English, and write out his correct form. \\\\\n",
      "shuffle_sentences & Your task is to correct the input sentence and write out his correct form. Given an incorrect English sentence. \\\\\n",
      "shuffle_words & is correct form. Given write sentence. his Your the English and incorrect out to correct task an sentence input \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "print(df_compares.style.to_latex(hrules=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2 0 1 8'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "tokenizer.decode(10434)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['It', 'was', 'a', 'beautiful', 'day', ',', 'perfect', 'for', 'a', 'trip', '.']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel, BertForMaskedLM\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "tokenizer.tokenize(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fill_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel, BertForMaskedLM\n",
    " \n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "input_txt = data_crud\n",
    "inputs = tokenizer(input_txt, return_tensors='pt', truncation=True, max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = inputs['input_ids'][0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertForMaskedLM.from_pretrained('bert-base-cased')\n",
    " \n",
    "outputs = model(**inputs)\n",
    "predictions = outputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[119, 119, 1541, 1108, 1216, 170, 2712, 1285, 117, 1103, 3264, 1285, 1111, 170, 1263, 3868, 119]\n",
      "['It', 'really', 'was', 'such', 'a', 'beautiful', 'day', ',', 'the', 'perfect', 'day', 'for', 'a', 'long', 'trip', '.']\n"
     ]
    }
   ],
   "source": [
    "_, sorted_idx = predictions[0].sort(dim=-1, descending=True)\n",
    "input_ids = inputs['input_ids'][0].numpy()\n",
    "for k in range(1):\n",
    "    predicted_index = [sorted_idx[i, k].item() for i in range(0, len(predictions[0])-1)]\n",
    "    print(predicted_index)\n",
    "    predicted_token = []\n",
    "    for x in range(1, len(predictions[0])-1):\n",
    "        if input_ids[x] == 103:\n",
    "            predicted_token.append(tokenizer.convert_ids_to_tokens([predicted_index[x]])[0])\n",
    "        else:\n",
    "            predicted_token.append(tokenizer.convert_ids_to_tokens([input_ids[x]])[0])\n",
    "    print(predicted_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It really was such a beautiful day , the perfect day for a long trip .\n"
     ]
    }
   ],
   "source": [
    "tokens = []\n",
    "for token in predicted_token:\n",
    "    if token.startswith('##'):\n",
    "        tokens[-1] = tokens[-1] + token[2:]\n",
    "    else:\n",
    "        tokens.append(token)\n",
    "print(\" \".join(tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shuffle sentences "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import random\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"Read the passage and find the corresponding pronoun for the given name. The pronoun should match the given blank(_). The word between ** ** is the target name. The pronoun should be one of 'her', 'him', 'he', 'she' and 'his' with proper casing based on the position in the passage.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"The pronoun should be one of 'her', 'him', 'he', 'she' and 'his' with proper casing based on the position in the passage.\",\n",
       " 'Read the passage and find the corresponding pronoun for the given name.',\n",
       " 'The pronoun should match the given blank(_).',\n",
       " 'The word between ** ** is the target name.']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents = list(map(str, doc.sents))\n",
    "random.shuffle(sents)\n",
    "sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read the passage and find the corresponding pronoun for the given name.\n",
      "The pronoun should match the given blank(_).\n",
      "The word between ** ** is the target name.\n",
      "The pronoun should be one of 'her', 'him', 'he', 'she' and 'his' with proper casing based on the position in the passage.\n"
     ]
    }
   ],
   "source": [
    "for sent in list(doc.sents):\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Title Generation']\n",
      "['Cause Effect Classification']\n",
      "['Textual Entailment']\n",
      "['Cause Effect Classification']\n",
      "['Answerability Classification']\n",
      "['Cause Effect Classification']\n",
      "['Cause Effect Classification']\n",
      "['Cause Effect Classification']\n",
      "['Cause Effect Classification']\n",
      "['Cause Effect Classification']\n",
      "['Cause Effect Classification']\n",
      "['Cause Effect Classification']\n",
      "['Cause Effect Classification']\n",
      "['Cause Effect Classification']\n",
      "['Cause Effect Classification']\n",
      "['Cause Effect Classification']\n",
      "['Cause Effect Classification']\n",
      "['Cause Effect Classification']\n",
      "['Cause Effect Classification']\n",
      "['Cause Effect Classification']\n",
      "['Cause Effect Classification']\n",
      "['Cause Effect Classification']\n",
      "['Cause Effect Classification']\n",
      "['Cause Effect Classification']\n",
      "['Cause Effect Classification']\n",
      "['Cause Effect Classification']\n",
      "['Cause Effect Classification']\n",
      "['Cause Effect Classification']\n",
      "['Cause Effect Classification']\n",
      "['Cause Effect Classification']\n",
      "['Textual Entailment']\n",
      "['Cause Effect Classification']\n",
      "['Cause Effect Classification']\n",
      "['Textual Entailment']\n",
      "['Cause Effect Classification']\n",
      "defaultdict(<class 'int'>, {'Title Generation': 1, 'Cause Effect Classification': 30, 'Textual Entailment': 3, 'Answerability Classification': 1})\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import collections\n",
    "c = collections.defaultdict(int)\n",
    "with open(\"/home/gujiashe/Tk-Instruct/data/splits/xlingual/test_tasks.txt\", encoding=\"utf-8\") as split_f:\n",
    "    for line in split_f:\n",
    "        task_name = line.strip()\n",
    "        task_path = os.path.join(\"/home/gujiashe/Tk-Instruct/data/tasks\", task_name + \".json\")\n",
    "        \n",
    "        with open(task_path, encoding=\"utf-8\") as task_f:\n",
    "            s = task_f.read()\n",
    "            task_data = json.loads(s)\n",
    "            print(task_data[\"Categories\"])\n",
    "            c[task_data[\"Categories\"][0]] += 1\n",
    "print(c)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bc2c0cd89e4ba02e191b1e7889aaaf3c8919053db7e24df61ffe975264e317e1"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
